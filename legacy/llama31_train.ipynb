{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -U transformers \n",
    "!pip install -U datasets \n",
    "!pip install -U accelerate \n",
    "!pip install -U peft \n",
    "!pip install -U trl \n",
    "!pip install -U bitsandbytes \n",
    "!pip install -U wandb "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-04T21:38:57.174386Z",
     "start_time": "2024-11-04T21:37:46.268019Z"
    }
   },
   "id": "7ec273b1d3add3a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (4.34.0)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.46.1-py3-none-any.whl.metadata (44 kB)\n",
      "     ---------------------------------------- 0.0/44.1 kB ? eta -:--:--\n",
      "     ----------------------------------- -- 41.0/44.1 kB 991.0 kB/s eta 0:00:01\n",
      "     -------------------------------------- 44.1/44.1 kB 736.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.2-cp311-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from requests->transformers) (2024.6.2)\n",
      "Downloading transformers-4.46.1-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.0 MB 1.9 MB/s eta 0:00:06\n",
      "   ---------------------------------------- 0.1/10.0 MB 1.6 MB/s eta 0:00:07\n",
      "    --------------------------------------- 0.2/10.0 MB 1.5 MB/s eta 0:00:07\n",
      "    --------------------------------------- 0.2/10.0 MB 1.5 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.3/10.0 MB 1.4 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.4/10.0 MB 1.4 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.4/10.0 MB 1.4 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.5/10.0 MB 1.4 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.6/10.0 MB 1.4 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.6/10.0 MB 1.4 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.7/10.0 MB 1.4 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.7/10.0 MB 1.4 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 0.8/10.0 MB 1.4 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 0.9/10.0 MB 1.4 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 0.9/10.0 MB 1.4 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 1.0/10.0 MB 1.4 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.0/10.0 MB 1.4 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.1/10.0 MB 1.4 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.2/10.0 MB 1.4 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.2/10.0 MB 1.4 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 1.3/10.0 MB 1.3 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 1.4/10.0 MB 1.4 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 1.4/10.0 MB 1.3 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 1.5/10.0 MB 1.3 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 1.6/10.0 MB 1.3 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 1.6/10.0 MB 1.4 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 1.7/10.0 MB 1.3 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 1.7/10.0 MB 1.4 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 1.8/10.0 MB 1.3 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 1.9/10.0 MB 1.4 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 1.9/10.0 MB 1.3 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 2.0/10.0 MB 1.3 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 2.0/10.0 MB 1.3 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 2.1/10.0 MB 1.4 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 2.2/10.0 MB 1.3 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 2.2/10.0 MB 1.3 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 2.3/10.0 MB 1.3 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 2.3/10.0 MB 1.3 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 2.4/10.0 MB 1.3 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 2.5/10.0 MB 1.4 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 2.5/10.0 MB 1.3 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 2.6/10.0 MB 1.3 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 2.7/10.0 MB 1.3 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 2.7/10.0 MB 1.3 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 2.8/10.0 MB 1.3 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 2.8/10.0 MB 1.3 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 1.3 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 1.3 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 3.0/10.0 MB 1.3 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 3.1/10.0 MB 1.3 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 3.1/10.0 MB 1.3 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 3.2/10.0 MB 1.3 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 3.2/10.0 MB 1.3 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 3.3/10.0 MB 1.3 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 3.4/10.0 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 3.4/10.0 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 3.5/10.0 MB 1.3 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 3.6/10.0 MB 1.3 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 3.6/10.0 MB 1.3 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 3.7/10.0 MB 1.3 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 3.8/10.0 MB 1.3 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 3.8/10.0 MB 1.3 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 3.9/10.0 MB 1.3 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 3.9/10.0 MB 1.3 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.0/10.0 MB 1.3 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 4.1/10.0 MB 1.3 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 4.1/10.0 MB 1.3 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 4.2/10.0 MB 1.3 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 4.3/10.0 MB 1.3 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 4.3/10.0 MB 1.3 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 4.4/10.0 MB 1.3 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 4.5/10.0 MB 1.3 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 4.5/10.0 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 4.6/10.0 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 4.6/10.0 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 4.7/10.0 MB 1.3 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 4.8/10.0 MB 1.3 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 4.8/10.0 MB 1.3 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 4.9/10.0 MB 1.3 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 5.0/10.0 MB 1.3 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 5.0/10.0 MB 1.3 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 5.1/10.0 MB 1.3 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 5.2/10.0 MB 1.3 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 5.2/10.0 MB 1.3 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 5.3/10.0 MB 1.3 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 5.3/10.0 MB 1.3 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 5.4/10.0 MB 1.3 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 5.5/10.0 MB 1.4 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 5.5/10.0 MB 1.4 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 5.6/10.0 MB 1.4 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 5.7/10.0 MB 1.4 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 5.7/10.0 MB 1.4 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 5.8/10.0 MB 1.4 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 5.8/10.0 MB 1.3 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 5.9/10.0 MB 1.3 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 6.0/10.0 MB 1.4 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 6.0/10.0 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 6.1/10.0 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 6.2/10.0 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 6.2/10.0 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 6.3/10.0 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 6.3/10.0 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 6.4/10.0 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 6.5/10.0 MB 1.3 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 6.5/10.0 MB 1.4 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 6.6/10.0 MB 1.4 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 6.7/10.0 MB 1.4 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 6.7/10.0 MB 1.4 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 6.8/10.0 MB 1.4 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 6.9/10.0 MB 1.4 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 6.9/10.0 MB 1.4 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.0/10.0 MB 1.4 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 7.0/10.0 MB 1.4 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 7.1/10.0 MB 1.4 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 7.2/10.0 MB 1.4 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 7.2/10.0 MB 1.4 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 7.3/10.0 MB 1.4 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 7.4/10.0 MB 1.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 7.4/10.0 MB 1.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 7.5/10.0 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 7.5/10.0 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 7.6/10.0 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 7.7/10.0 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 7.8/10.0 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 7.8/10.0 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 7.9/10.0 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 7.9/10.0 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 8.0/10.0 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 8.0/10.0 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 8.1/10.0 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 8.2/10.0 MB 1.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 8.2/10.0 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 8.3/10.0 MB 1.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 8.3/10.0 MB 1.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 8.4/10.0 MB 1.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 8.5/10.0 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 8.5/10.0 MB 1.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 8.6/10.0 MB 1.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 8.7/10.0 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 8.7/10.0 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.8/10.0 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.8/10.0 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.9/10.0 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.0/10.0 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.0/10.0 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.1/10.0 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.1/10.0 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.2/10.0 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.3/10.0 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.3/10.0 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.4/10.0 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.5/10.0 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.5/10.0 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.6/10.0 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.7/10.0 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.7/10.0 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.8/10.0 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.8/10.0 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.9/10.0 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.0 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.0 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 1.3 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.20.2-cp311-none-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/2.4 MB 1.9 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.1/2.4 MB 1.6 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.2/2.4 MB 1.5 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.3/2.4 MB 1.3 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.3/2.4 MB 1.3 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.4/2.4 MB 1.4 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.4/2.4 MB 1.4 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.5/2.4 MB 1.4 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.6/2.4 MB 1.4 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.6/2.4 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.7/2.4 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 0.8/2.4 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 0.8/2.4 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 0.9/2.4 MB 1.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 0.9/2.4 MB 1.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 1.0/2.4 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.1/2.4 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.1/2.4 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.2/2.4 MB 1.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.3/2.4 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.3/2.4 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.4/2.4 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.5/2.4 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.5/2.4 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.6/2.4 MB 1.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.6/2.4 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.7/2.4 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.8/2.4 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.9/2.4 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.9/2.4 MB 1.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.0/2.4 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.0/2.4 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.1/2.4 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.2/2.4 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.2/2.4 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.3/2.4 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.4/2.4 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 1.4 MB/s eta 0:00:00\n",
      "Installing collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.14.1\n",
      "    Uninstalling tokenizers-0.14.1:\n",
      "      Successfully uninstalled tokenizers-0.14.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.34.0\n",
      "    Uninstalling transformers-4.34.0:\n",
      "      Successfully uninstalled transformers-4.34.0\n",
      "Successfully installed tokenizers-0.20.2 transformers-4.46.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'E:\\PyCharm Community Edition 2021.1.1\\projects\\LLM_LoRa\\venv\\Lib\\site-packages\\~~kenizers'.\n",
      "  You can safely remove it manually.\n",
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (3.0.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from datasets) (3.15.4)\n",
      "Requirement already satisfied: numpy>=1.17 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from datasets) (0.26.2)\n",
      "Requirement already satisfied: packaging in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.6.2)\n",
      "Requirement already satisfied: colorama in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "   ---------------------------------------- 0.0/480.6 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 30.7/480.6 kB ? eta -:--:--\n",
      "   ------- -------------------------------- 92.2/480.6 kB 1.7 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 153.6/480.6 kB 1.5 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 235.5/480.6 kB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 307.2/480.6 kB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 368.6/480.6 kB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 430.1/480.6 kB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 480.6/480.6 kB 1.5 MB/s eta 0:00:00\n",
      "Installing collected packages: datasets\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 3.0.1\n",
      "    Uninstalling datasets-3.0.1:\n",
      "      Successfully uninstalled datasets-3.0.1\n",
      "Successfully installed datasets-3.1.0\n",
      "Requirement already satisfied: accelerate in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (0.23.0)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.1.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from accelerate) (2.3.1+cu118)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from accelerate) (0.26.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.5.0)\n",
      "Requirement already satisfied: requests in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: sympy in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
      "Requirement already satisfied: networkx in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->accelerate) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->accelerate) (2021.13.0)\n",
      "Requirement already satisfied: colorama in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.6.2)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading accelerate-1.1.0-py3-none-any.whl (333 kB)\n",
      "   ---------------------------------------- 0.0/333.2 kB ? eta -:--:--\n",
      "   ---- ---------------------------------- 41.0/333.2 kB 960.0 kB/s eta 0:00:01\n",
      "   ------------- -------------------------- 112.6/333.2 kB 1.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 194.6/333.2 kB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 256.0/333.2 kB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 317.4/333.2 kB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 333.2/333.2 kB 1.4 MB/s eta 0:00:00\n",
      "Installing collected packages: accelerate\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.23.0\n",
      "    Uninstalling accelerate-0.23.0:\n",
      "      Successfully uninstalled accelerate-0.23.0\n",
      "Successfully installed accelerate-1.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (0.5.0)\n",
      "Collecting peft\n",
      "  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from peft) (24.1)\n",
      "Requirement already satisfied: psutil in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from peft) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from peft) (2.3.1+cu118)\n",
      "Requirement already satisfied: transformers in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from peft) (4.46.1)\n",
      "Requirement already satisfied: tqdm in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from peft) (4.66.4)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from peft) (1.1.0)\n",
      "Requirement already satisfied: safetensors in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from peft) (0.4.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from peft) (0.26.2)\n",
      "Requirement already satisfied: filelock in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (2024.5.0)\n",
      "Requirement already satisfied: requests in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
      "Requirement already satisfied: sympy in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from torch>=1.13.0->peft) (1.12.1)\n",
      "Requirement already satisfied: networkx in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from torch>=1.13.0->peft) (2021.4.0)\n",
      "Requirement already satisfied: colorama in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from tqdm->peft) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from transformers->peft) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from transformers->peft) (0.20.2)\n",
      "Requirement already satisfied: intel-openmp==2021.* in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.13.0->peft) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.13.0->peft) (2021.13.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.6.2)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Downloading peft-0.13.2-py3-none-any.whl (320 kB)\n",
      "   ---------------------------------------- 0.0/320.7 kB ? eta -:--:--\n",
      "   ---- ---------------------------------- 41.0/320.7 kB 991.0 kB/s eta 0:00:01\n",
      "   -------------- ------------------------- 112.6/320.7 kB 1.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 174.1/320.7 kB 1.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 235.5/320.7 kB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 307.2/320.7 kB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 320.7/320.7 kB 1.3 MB/s eta 0:00:00\n",
      "Installing collected packages: peft\n",
      "  Attempting uninstall: peft\n",
      "    Found existing installation: peft 0.5.0\n",
      "    Uninstalling peft-0.5.0:\n",
      "      Successfully uninstalled peft-0.5.0\n",
      "Successfully installed peft-0.13.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: trl in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (0.11.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting trl\n",
      "  Downloading trl-0.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: accelerate>=0.34.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from trl) (1.1.0)\n",
      "Requirement already satisfied: datasets>=2.21.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from trl) (3.1.0)\n",
      "Requirement already satisfied: rich in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from trl) (13.9.1)\n",
      "Requirement already satisfied: transformers>=4.46.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from trl) (4.46.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from accelerate>=0.34.0->trl) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from accelerate>=0.34.0->trl) (24.1)\n",
      "Requirement already satisfied: psutil in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from accelerate>=0.34.0->trl) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from accelerate>=0.34.0->trl) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from accelerate>=0.34.0->trl) (2.3.1+cu118)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from accelerate>=0.34.0->trl) (0.26.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from accelerate>=0.34.0->trl) (0.4.3)\n",
      "Requirement already satisfied: filelock in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from datasets>=2.21.0->trl) (3.15.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from datasets>=2.21.0->trl) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from datasets>=2.21.0->trl) (0.3.8)\n",
      "Requirement already satisfied: pandas in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from datasets>=2.21.0->trl) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from datasets>=2.21.0->trl) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from datasets>=2.21.0->trl) (4.66.4)\n",
      "Requirement already satisfied: xxhash in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from datasets>=2.21.0->trl) (3.4.1)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from datasets>=2.21.0->trl) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.21.0->trl) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from datasets>=2.21.0->trl) (3.9.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from transformers>=4.46.0->trl) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from transformers>=4.46.0->trl) (0.20.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from rich->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from rich->trl) (2.18.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from aiohttp->datasets>=2.21.0->trl) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from aiohttp->datasets>=2.21.0->trl) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from aiohttp->datasets>=2.21.0->trl) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from aiohttp->datasets>=2.21.0->trl) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from aiohttp->datasets>=2.21.0->trl) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate>=0.34.0->trl) (4.12.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (2024.6.2)\n",
      "Requirement already satisfied: sympy in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (1.12.1)\n",
      "Requirement already satisfied: networkx in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (3.3)\n",
      "Requirement already satisfied: jinja2 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (3.1.4)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (2021.4.0)\n",
      "Requirement already satisfied: colorama in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from tqdm>=4.66.3->datasets>=2.21.0->trl) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from pandas->datasets>=2.21.0->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from pandas->datasets>=2.21.0->trl) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from pandas->datasets>=2.21.0->trl) (2024.1)\n",
      "Requirement already satisfied: intel-openmp==2021.* in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->accelerate>=0.34.0->trl) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->accelerate>=0.34.0->trl) (2021.13.0)\n",
      "Requirement already satisfied: six>=1.5 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.21.0->trl) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate>=0.34.0->trl) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate>=0.34.0->trl) (1.3.0)\n",
      "Downloading trl-0.12.0-py3-none-any.whl (310 kB)\n",
      "   ---------------------------------------- 0.0/310.2 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 30.7/310.2 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 92.2/310.2 kB 1.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 153.6/310.2 kB 1.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 225.3/310.2 kB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 286.7/310.2 kB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 310.2/310.2 kB 1.3 MB/s eta 0:00:00\n",
      "Installing collected packages: trl\n",
      "  Attempting uninstall: trl\n",
      "    Found existing installation: trl 0.11.1\n",
      "    Uninstalling trl-0.11.1:\n",
      "      Successfully uninstalled trl-0.11.1\n",
      "Successfully installed trl-0.12.0\n",
      "Requirement already satisfied: bitsandbytes in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (0.44.1)\n",
      "Requirement already satisfied: torch in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from bitsandbytes) (2.3.1+cu118)\n",
      "Requirement already satisfied: numpy in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: filelock in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from torch->bitsandbytes) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from torch->bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: sympy in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from torch->bitsandbytes) (1.12.1)\n",
      "Requirement already satisfied: networkx in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from torch->bitsandbytes) (3.3)\n",
      "Requirement already satisfied: jinja2 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from torch->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: fsspec in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from torch->bitsandbytes) (2024.5.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from torch->bitsandbytes) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->bitsandbytes) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->bitsandbytes) (2021.13.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (0.18.3)\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.18.5-py3-none-win_amd64.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from wandb) (4.2.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from wandb) (5.28.2)\n",
      "Requirement already satisfied: psutil>=5.0.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from wandb) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from wandb) (2.15.0)\n",
      "Requirement already satisfied: setproctitle in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from wandb) (68.2.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from wandb) (4.12.2)\n",
      "Requirement already satisfied: colorama in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2024.6.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in e:\\pycharm community edition 2021.1.1\\projects\\llm_lora\\venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "Downloading wandb-0.18.5-py3-none-win_amd64.whl (15.4 MB)\n",
      "   ---------------------------------------- 0.0/15.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/15.4 MB 1.9 MB/s eta 0:00:09\n",
      "   ---------------------------------------- 0.1/15.4 MB 1.3 MB/s eta 0:00:12\n",
      "   ---------------------------------------- 0.2/15.4 MB 1.1 MB/s eta 0:00:14\n",
      "    --------------------------------------- 0.2/15.4 MB 1.3 MB/s eta 0:00:13\n",
      "    --------------------------------------- 0.3/15.4 MB 1.3 MB/s eta 0:00:12\n",
      "    --------------------------------------- 0.3/15.4 MB 1.3 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 0.4/15.4 MB 1.2 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 0.5/15.4 MB 1.3 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 0.5/15.4 MB 1.3 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 0.6/15.4 MB 1.3 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 0.6/15.4 MB 1.3 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 0.7/15.4 MB 1.3 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 0.8/15.4 MB 1.3 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 0.8/15.4 MB 1.3 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 0.9/15.4 MB 1.3 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 1.0/15.4 MB 1.3 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 1.0/15.4 MB 1.3 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 1.1/15.4 MB 1.3 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 1.1/15.4 MB 1.3 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 1.2/15.4 MB 1.3 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 1.3/15.4 MB 1.3 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 1.3/15.4 MB 1.3 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 1.4/15.4 MB 1.3 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 1.4/15.4 MB 1.3 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 1.5/15.4 MB 1.3 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 1.5/15.4 MB 1.3 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 1.6/15.4 MB 1.3 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 1.7/15.4 MB 1.3 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 1.7/15.4 MB 1.3 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 1.8/15.4 MB 1.3 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 1.8/15.4 MB 1.3 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 1.9/15.4 MB 1.3 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 2.0/15.4 MB 1.3 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 2.0/15.4 MB 1.3 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 2.1/15.4 MB 1.3 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 2.2/15.4 MB 1.3 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 2.2/15.4 MB 1.3 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 2.3/15.4 MB 1.3 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 2.3/15.4 MB 1.3 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 2.4/15.4 MB 1.3 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 2.4/15.4 MB 1.3 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 2.5/15.4 MB 1.3 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 2.6/15.4 MB 1.3 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 2.6/15.4 MB 1.3 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 2.7/15.4 MB 1.3 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 2.8/15.4 MB 1.3 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 2.8/15.4 MB 1.3 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 2.9/15.4 MB 1.3 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 2.9/15.4 MB 1.3 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 3.0/15.4 MB 1.3 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 3.1/15.4 MB 1.3 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 3.1/15.4 MB 1.3 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 3.2/15.4 MB 1.3 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 3.2/15.4 MB 1.3 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 3.3/15.4 MB 1.3 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 3.3/15.4 MB 1.3 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 3.4/15.4 MB 1.3 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 3.5/15.4 MB 1.3 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 3.5/15.4 MB 1.3 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 3.6/15.4 MB 1.3 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 3.6/15.4 MB 1.3 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 3.7/15.4 MB 1.3 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 3.8/15.4 MB 1.3 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 3.8/15.4 MB 1.3 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 3.9/15.4 MB 1.3 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 3.9/15.4 MB 1.3 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 4.0/15.4 MB 1.3 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 4.1/15.4 MB 1.3 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 4.1/15.4 MB 1.3 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 4.2/15.4 MB 1.3 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 4.2/15.4 MB 1.3 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 4.3/15.4 MB 1.3 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 4.3/15.4 MB 1.3 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 4.4/15.4 MB 1.3 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 4.5/15.4 MB 1.3 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 4.5/15.4 MB 1.3 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 4.6/15.4 MB 1.3 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 4.6/15.4 MB 1.3 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 4.7/15.4 MB 1.3 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 4.8/15.4 MB 1.3 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 4.8/15.4 MB 1.3 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 4.9/15.4 MB 1.3 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 4.9/15.4 MB 1.3 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 5.0/15.4 MB 1.3 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 5.0/15.4 MB 1.3 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 5.1/15.4 MB 1.3 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 5.2/15.4 MB 1.3 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 5.2/15.4 MB 1.3 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 5.3/15.4 MB 1.3 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 5.3/15.4 MB 1.3 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 5.4/15.4 MB 1.3 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 5.5/15.4 MB 1.3 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 5.5/15.4 MB 1.3 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 5.6/15.4 MB 1.3 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 5.7/15.4 MB 1.3 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 5.7/15.4 MB 1.3 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 5.8/15.4 MB 1.3 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 5.8/15.4 MB 1.3 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 5.9/15.4 MB 1.3 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 6.0/15.4 MB 1.3 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 6.0/15.4 MB 1.3 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 6.1/15.4 MB 1.3 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 6.1/15.4 MB 1.3 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 6.2/15.4 MB 1.3 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 6.3/15.4 MB 1.3 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 6.3/15.4 MB 1.3 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 6.4/15.4 MB 1.3 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 6.4/15.4 MB 1.3 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 6.5/15.4 MB 1.3 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 6.6/15.4 MB 1.3 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 6.6/15.4 MB 1.3 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 6.7/15.4 MB 1.3 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 6.7/15.4 MB 1.3 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 6.8/15.4 MB 1.3 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 6.8/15.4 MB 1.3 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 6.9/15.4 MB 1.3 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 7.0/15.4 MB 1.3 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 7.0/15.4 MB 1.3 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 7.1/15.4 MB 1.3 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 7.1/15.4 MB 1.3 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 7.2/15.4 MB 1.3 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 7.3/15.4 MB 1.3 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 7.3/15.4 MB 1.3 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 7.4/15.4 MB 1.3 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 7.4/15.4 MB 1.3 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 7.5/15.4 MB 1.3 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 7.6/15.4 MB 1.3 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 7.6/15.4 MB 1.3 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 7.7/15.4 MB 1.3 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 7.7/15.4 MB 1.3 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 7.8/15.4 MB 1.3 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 7.9/15.4 MB 1.3 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 7.9/15.4 MB 1.3 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 8.0/15.4 MB 1.3 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 8.0/15.4 MB 1.3 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 8.1/15.4 MB 1.3 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 8.2/15.4 MB 1.3 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 8.2/15.4 MB 1.3 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 8.3/15.4 MB 1.3 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 8.3/15.4 MB 1.3 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 8.4/15.4 MB 1.3 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 8.5/15.4 MB 1.3 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 8.5/15.4 MB 1.3 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 8.6/15.4 MB 1.3 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 8.7/15.4 MB 1.3 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 8.7/15.4 MB 1.3 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 8.8/15.4 MB 1.3 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 8.8/15.4 MB 1.3 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 8.9/15.4 MB 1.3 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 8.9/15.4 MB 1.3 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 9.0/15.4 MB 1.3 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 9.1/15.4 MB 1.3 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 9.1/15.4 MB 1.3 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 9.2/15.4 MB 1.3 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 9.2/15.4 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 9.3/15.4 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 9.4/15.4 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 9.4/15.4 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 9.5/15.4 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 9.5/15.4 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 9.6/15.4 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 9.7/15.4 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 9.7/15.4 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 9.8/15.4 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 9.8/15.4 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 9.9/15.4 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 10.0/15.4 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 10.0/15.4 MB 1.3 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 10.1/15.4 MB 1.3 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 10.1/15.4 MB 1.3 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 10.2/15.4 MB 1.3 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 10.3/15.4 MB 1.3 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 10.3/15.4 MB 1.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 10.4/15.4 MB 1.3 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 10.4/15.4 MB 1.3 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 10.5/15.4 MB 1.3 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 10.6/15.4 MB 1.3 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 10.6/15.4 MB 1.3 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 10.7/15.4 MB 1.3 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 10.7/15.4 MB 1.3 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 10.8/15.4 MB 1.3 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 10.9/15.4 MB 1.3 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 10.9/15.4 MB 1.3 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 11.0/15.4 MB 1.3 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 11.0/15.4 MB 1.3 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 11.1/15.4 MB 1.3 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 11.1/15.4 MB 1.3 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 11.2/15.4 MB 1.3 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 11.2/15.4 MB 1.3 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 11.3/15.4 MB 1.3 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 11.4/15.4 MB 1.3 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 11.4/15.4 MB 1.3 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 11.5/15.4 MB 1.3 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 11.5/15.4 MB 1.3 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 11.6/15.4 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 11.7/15.4 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 11.7/15.4 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 11.8/15.4 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 11.8/15.4 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 11.9/15.4 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 12.0/15.4 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 12.0/15.4 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 12.1/15.4 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 12.1/15.4 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 12.2/15.4 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 12.2/15.4 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 12.3/15.4 MB 1.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 12.4/15.4 MB 1.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 12.4/15.4 MB 1.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 12.5/15.4 MB 1.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 12.5/15.4 MB 1.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 12.6/15.4 MB 1.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 12.7/15.4 MB 1.3 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 12.7/15.4 MB 1.3 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 12.8/15.4 MB 1.3 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 12.9/15.4 MB 1.3 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 12.9/15.4 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 13.0/15.4 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 13.1/15.4 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 13.1/15.4 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 13.2/15.4 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 13.2/15.4 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 13.3/15.4 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 13.3/15.4 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 13.4/15.4 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 13.4/15.4 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 13.5/15.4 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 13.6/15.4 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 13.6/15.4 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 13.7/15.4 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 13.8/15.4 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 13.8/15.4 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 13.9/15.4 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 13.9/15.4 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 14.0/15.4 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 14.0/15.4 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 14.1/15.4 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 14.2/15.4 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.2/15.4 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.3/15.4 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.4/15.4 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.4/15.4 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.5/15.4 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.5/15.4 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.6/15.4 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.7/15.4 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.7/15.4 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.8/15.4 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.8/15.4 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.9/15.4 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.0/15.4 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.0/15.4 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.1/15.4 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.1/15.4 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.2/15.4 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.2/15.4 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.3/15.4 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.4/15.4 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.4/15.4 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.4/15.4 MB 1.3 MB/s eta 0:00:00\n",
      "Installing collected packages: wandb\n",
      "  Attempting uninstall: wandb\n",
      "    Found existing installation: wandb 0.18.3\n",
      "    Uninstalling wandb-0.18.3:\n",
      "      Successfully uninstalled wandb-0.18.3\n",
      "Successfully installed wandb-0.18.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'E:\\PyCharm Community Edition 2021.1.1\\projects\\LLM_LoRa\\venv\\Lib\\site-packages\\~andb'.\n",
      "  You can safely remove it manually.\n",
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-23T09:38:28.136136Z",
     "start_time": "2024-09-23T09:38:28.132940Z"
    }
   },
   "id": "649f115e8e6fa4f0",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "import torch, wandb\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    ")\n",
    "\n",
    "from trl import SFTTrainer\n",
    "from dataclasses import dataclass"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-08T08:33:57.440318Z",
     "start_time": "2024-11-08T08:33:30.040794Z"
    }
   },
   "id": "70056fe4b95e9254",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "from huggingface_hub import login\n",
    "# from kaggle_secrets import UserSecretsClient\n",
    "from training_model.private_api import WANB_API, HUGGING_FACE_API\n",
    "# user_secrets = UserSecretsClient()\n",
    "\n",
    "# hf_token = user_secrets.get_secret(\"huggingface_token\")\n",
    "hf_token = HUGGING_FACE_API\n",
    "\n",
    "login(token = hf_token)\n",
    "\n",
    "# wb_token = user_secrets.get_secret(\"wandb_api_key\")\n",
    "wb_token = WANB_API\n",
    "\n",
    "wandb.login(key=wb_token)\n",
    "run = wandb.init(\n",
    "    project='Fine-tune Llama 3.1 8B on Dataset for game', \n",
    "    job_type=\"training\", \n",
    "    anonymous=\"allow\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-08T08:34:01.657421Z",
     "start_time": "2024-11-08T08:33:57.441322Z"
    }
   },
   "id": "7c41cc390454b230",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: ser13volk (ser13volk-rtu-mirea). Use `wandb login --relogin` to force relogin\n",
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\user\\_netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>E:\\PyCharm Community Edition 2021.1.1\\projects\\LLM_LoRa\\LLM_LoRa\\wandb\\run-20241108_113400-g57x0w4b</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ser13volk-rtu-mirea/Fine-tune%20Llama%203.1%208B%20on%20Dataset%20for%20game/runs/g57x0w4b' target=\"_blank\">gallant-totem-14</a></strong> to <a href='https://wandb.ai/ser13volk-rtu-mirea/Fine-tune%20Llama%203.1%208B%20on%20Dataset%20for%20game' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/ser13volk-rtu-mirea/Fine-tune%20Llama%203.1%208B%20on%20Dataset%20for%20game' target=\"_blank\">https://wandb.ai/ser13volk-rtu-mirea/Fine-tune%20Llama%203.1%208B%20on%20Dataset%20for%20game</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/ser13volk-rtu-mirea/Fine-tune%20Llama%203.1%208B%20on%20Dataset%20for%20game/runs/g57x0w4b' target=\"_blank\">https://wandb.ai/ser13volk-rtu-mirea/Fine-tune%20Llama%203.1%208B%20on%20Dataset%20for%20game/runs/g57x0w4b</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading model and tokenizer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a9da87ebdc3bf8e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "!huggingface-cli download meta-llama/Meta-Llama-3.1-8B-Instruct --include \"original/*\" --local-dir Meta-Llama-3.1-8B-Instruct"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T20:12:52.321860Z",
     "start_time": "2024-09-30T20:12:49.775333Z"
    }
   },
   "id": "7f73c19400f3fe66",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    # model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "    # model_name = \"aifeifei798/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored\"\n",
    "    model_name = \"IlyaGusev/saiga_llama3_8b\"\n",
    "    dataset_name = \"data/dataset_ru.json\"\n",
    "    # dataset_name = \"ruslanmv/ai-medical-chatbot\"\n",
    "    new_model = \"llama-3-8b-chat-vika\"\n",
    "    torch_dtype = torch.float16\n",
    "    attn_implementation = \"eager\"\n",
    "\n",
    "cfg = Config() "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-08T08:34:01.661540Z",
     "start_time": "2024-11-08T08:34:01.657421Z"
    }
   },
   "id": "34091b6893fa7eda",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=cfg.torch_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-08T08:34:01.669028Z",
     "start_time": "2024-11-08T08:34:01.662541Z"
    }
   },
   "id": "a62b8d9d7776674e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T11:28:20.026132Z",
     "start_time": "2024-11-08T09:52:20.931491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    cfg.model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=cfg.attn_implementation\n",
    ")"
   ],
   "id": "bfb5815445cda0d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c535780611a1420b8c9b66837bdbad02"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00001-of-00004.safetensors:  43%|####3     | 2.15G/4.98G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dfc7ee9858f447d58325d184a1b749ed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6a7cd1b646134fdf8864e29490197859"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0b587d334ffe4906987cf2ed68fae428"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9a02f307e9a4499be8e9f72ceeda3a6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e97c5e9f499440ce8d67ca04e530c227"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/277 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a406d5d25c124ee783e8c79e7696c984"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)\n",
    "# model, tokenizer = setup_chat_format(model, tokenizer)\n",
    "tokenizer.padding_side = 'right'\n",
    "tokenizer.padding_token = '<|pad|>'\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-08T11:28:25.564440Z",
     "start_time": "2024-11-08T11:28:20.026132Z"
    }
   },
   "id": "60c054c24a98a3a0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b5c36e3d9377404fae4df76e9926ca12"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d87568f6807c4bf6aeb5c2eb404a0dd4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/446 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "583661f423164ff7ad224328bd55a553"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Embedding(128256, 4096)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LoRA adapter"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8690c10088af39fb"
  },
  {
   "cell_type": "code",
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n",
    ")\n",
    "model = get_peft_model(model, peft_config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-08T11:28:25.994808Z",
     "start_time": "2024-11-08T11:28:25.565440Z"
    }
   },
   "id": "ce049e546f1481b9",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8865deaf498da5da"
  },
  {
   "cell_type": "code",
   "source": [
    "# def get_end_prompt(question):\n",
    "#     return f\"\"\"START\\n{question}\\nEND\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-05T10:50:40.448775Z",
     "start_time": "2024-11-05T10:50:40.444610Z"
    }
   },
   "id": "c4fbcc993b290e8e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "import json \n",
    "with open(cfg.dataset_name, 'r', encoding='utf-8') as file:\n",
    "    train_dataset = json.load(file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-08T11:28:26.012716Z",
     "start_time": "2024-11-08T11:28:25.996811Z"
    }
   },
   "id": "57c526d65506d3af",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T11:28:26.019612Z",
     "start_time": "2024-11-08T11:28:26.013699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "def get_user_prompt(data):\n",
    "    user_message = (\" ,    ,   'system'. \"\n",
    "                    \"     'user'.      'VIKA'. \"\n",
    "                    \"\\n\\n :\")\n",
    "    for message in data[\"History\"]:\n",
    "        user_message += f\"\\n{message}\"\n",
    "    user_message += f\"\\n\\n       .\\n :\\n , {', '.join(data['AvailableActions'])}\"\n",
    "    user_message += f\"\\n\\n   ,      .\\n :\\n{data['UserInput']}\"\n",
    "    return user_message\n",
    "\n",
    "def dataset_to_json(dataset, filename):\n",
    "    json_objects = []\n",
    "    system = dataset[\"system\"]\n",
    "    dataset = dataset[\"examples\"]\n",
    "    \n",
    "    with open(filename, 'w', encoding=\"utf-8\") as file:\n",
    "        file.write(\"\")\n",
    "    \n",
    "\n",
    "    for row in dataset.keys():        \n",
    "        system_message = system\n",
    "        user_message = get_user_prompt(dataset[row]['prompt'])\n",
    "        # user_message = str(dataset[row]['prompt'])\n",
    "        bot_message = str(dataset[row]['answer'])\n",
    "\n",
    "        json_object = {\n",
    "            \"system\": system_message,\n",
    "            \"user\": user_message,\n",
    "            \"bot\": bot_message\n",
    "        }\n",
    "\n",
    "        json_objects.append(json_object)\n",
    "        with open(filename, 'a', encoding='utf-8') as file:\n",
    "          file.write(json.dumps(json_object, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    return json_objects"
   ],
   "id": "e5a24f9926df5ad1",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T11:28:26.037007Z",
     "start_time": "2024-11-08T11:28:26.020610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(os.path.join(\"../data\", \"test_ru.json\"), 'r', encoding='utf-8') as file:\n",
    "    test_dataset = json.load(file)"
   ],
   "id": "820b90a78e4722f7",
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": "train_dataset",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-04T19:06:21.858219Z",
     "start_time": "2024-11-04T19:06:21.849203Z"
    }
   },
   "id": "ffb4f8574ac87dec",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'system': \"         .       .     JSON   'MessageText'  'Actions',     ( )   .   Actions   ,   .    }.         ,      .\",\n",
       " 'examples': {'topic0': {'prompt': {'History': [\"system: ' -        .       .     JSON   'MessageText'  'Actions',     ( )   .   Actions   ,   .    }.  -       ,      . \"],\n",
       "    'AvailableActions': [' '],\n",
       "    'UserInput': '  ?'},\n",
       "   'answer': {'MessageText': ', ,   .',\n",
       "    'Content': {'Action': ' '}}},\n",
       "  'topic1': {'prompt': {'History': [\"system: ' -        .       .     JSON   'MessageText'  'Actions',     ( )   .   Actions   ,   .    }.  -       ,      . \"],\n",
       "    'AvailableActions': [' '],\n",
       "    'UserInput': ' ?'},\n",
       "   'answer': {'MessageText': ' ,  -    .',\n",
       "    'Content': {'Action': ''}}},\n",
       "  'topic2': {'prompt': {'History': [\"system: ' -        .       .     JSON   'MessageText'  'Actions',     ( )   .   Actions   ,   .    }.  -       ,      . \"],\n",
       "    'AvailableActions': [' '],\n",
       "    'UserInput': ' '},\n",
       "   'answer': {'MessageText': '    :   ',\n",
       "    'Content': {'Action': ''}}},\n",
       "  'topic3': {'prompt': {'History': [\"system: ' -        .       .     JSON   'MessageText'  'Actions',     ( )   .   Actions   ,   .    }.  -       ,      . \"],\n",
       "    'AvailableActions': [' '],\n",
       "    'UserInput': ' '},\n",
       "   'answer': {'MessageText': '  ,   .',\n",
       "    'Content': {'Action': ''}}},\n",
       "  'topic4': {'prompt': {'History': [\"system: ' -        .       .     JSON   'MessageText'  'Actions',     ( )   .   Actions   ,   .    }.  -       ,      . \"],\n",
       "    'AvailableActions': [' ',\n",
       "     '   ',\n",
       "     '    ',\n",
       "     ' '],\n",
       "    'UserInput': ' '},\n",
       "   'answer': {'MessageText': '   ,   ?           .',\n",
       "    'Content': {'Action': ''}}},\n",
       "  'topic5': {'prompt': {'History': [\"system: ' -        .       .     JSON   'MessageText'  'Actions',     ( )   .   Actions   ,   .    }.  -       ,      . \",\n",
       "     \"user: '   ?'\",\n",
       "     \"VIKA: '  ,        .'\"],\n",
       "    'AvailableActions': [' ',\n",
       "     '   ',\n",
       "     '   -',\n",
       "     ' '],\n",
       "    'UserInput': '    ?'},\n",
       "   'answer': {'MessageText': '      .',\n",
       "    'Content': {'Action': ''}}},\n",
       "  'topic6': {'prompt': {'History': [\"system: ' -        .       .     JSON   'MessageText'  'Actions',     ( )   .   Actions   ,   .    }.  -       ,      . \"],\n",
       "    'AvailableActions': [' ',\n",
       "     '   ',\n",
       "     '   -',\n",
       "     ' '],\n",
       "    'UserInput': '   ?'},\n",
       "   'answer': {'MessageText': '  ,        .',\n",
       "    'Content': {'Action': ''}}},\n",
       "  'topic7': {'prompt': {'History': [\"system: ' -        .       .     JSON   'MessageText'  'Actions',     ( )   .   Actions   ,   .    }.  -       ,      . \",\n",
       "     \"user: ' .'\",\n",
       "     \"VIKA: ',   .'\"],\n",
       "    'AvailableActions': [' ',\n",
       "     '   ',\n",
       "     '   -',\n",
       "     ' '],\n",
       "    'UserInput': '  .   '},\n",
       "   'answer': {'MessageText': ' ,     . ,   .',\n",
       "    'Content': {'Action': ' '}}},\n",
       "  'topic8': {'prompt': {'History': [\"system: ' -        .       .     JSON   'MessageText'  'Actions',     ( )   .   Actions   ,   .    }.  -       ,      . \",\n",
       "     \"user:    ??'\",\n",
       "     \"VIKA: '  ,        .'\",\n",
       "     \"user: '    ?'\",\n",
       "     \"VIKA: '      .'\"],\n",
       "    'AvailableActions': [' ',\n",
       "     '   ',\n",
       "     '   -',\n",
       "     ' '],\n",
       "    'UserInput': '   ?  ?'},\n",
       "   'answer': {'MessageText': '      .',\n",
       "    'Content': {'Action': ''}}},\n",
       "  'topic9': {'prompt': {'History': [\"system: ' -        .       .     JSON   'MessageText'  'Actions',     ( )   .   Actions   ,   .    }.  -       ,      . \",\n",
       "     \"user:    ??'\",\n",
       "     \"VIKA: '  ,        .'\",\n",
       "     \"user: '    ?'\",\n",
       "     \"VIKA: '      .'\",\n",
       "     \"user: '   ?  ?'\",\n",
       "     \"VIKA: '      .'\"],\n",
       "    'AvailableActions': [' ',\n",
       "     '   ',\n",
       "     '   -',\n",
       "     ' '],\n",
       "    'UserInput': '    ,    ,   .'},\n",
       "   'answer': {'MessageText': ',         ...   ...        ,  ,     .        .',\n",
       "    'Content': {'Action': ''}}},\n",
       "  'topic10': {'prompt': {'History': [\"system: ' -        .       .     JSON   'MessageText'  'Actions',     ( )   .   Actions   ,   .    }.  -       ,      . \",\n",
       "     \"user:    ??'\",\n",
       "     \"VIKA: '  ,        .'\",\n",
       "     \"user: '    ?'\",\n",
       "     \"VIKA: '      .'\",\n",
       "     \"user: '   ?  ?'\",\n",
       "     \"VIKA: '      .'\",\n",
       "     \"user: '    ,    ,   .'\",\n",
       "     \"VIKA: ',         ...   ...        ,  ,     .       .'\"],\n",
       "    'AvailableActions': [' ',\n",
       "     '   ',\n",
       "     '   -',\n",
       "     ' '],\n",
       "    'UserInput': '  ?'},\n",
       "   'answer': {'MessageText': '.',\n",
       "    'Content': {'Action': ''}}},\n",
       "  'topic11': {'prompt': {'History': [\"system: ' -        .       .     JSON   'MessageText'  'Actions',     ( )   .   Actions   ,   .    }.  -       ,      . \",\n",
       "     \"user:    ??'\",\n",
       "     \"VIKA: '  ,        .'\",\n",
       "     \"user: '    ?'\",\n",
       "     \"VIKA: '      .'\",\n",
       "     \"user: '   ?  ?'\",\n",
       "     \"VIKA: '      .'\",\n",
       "     \"user: '    ,    ,   .'\",\n",
       "     \"VIKA: ',         ...   ...        ,  ,     .       .'\",\n",
       "     \"user: '  ?'\",\n",
       "     \"VIKA: '.'\"],\n",
       "    'AvailableActions': [' ',\n",
       "     '   ',\n",
       "     '   -',\n",
       "     ' '],\n",
       "    'UserInput': '   ?'},\n",
       "   'answer': {'MessageText': '...', 'Content': {'Action': ''}}},\n",
       "  'topic12': {'prompt': {'History': [\"system: ' -        .       .     JSON   'MessageText'  'Actions',     ( )   .   Actions   ,   .    }.  -       ,      . \",\n",
       "     \"user:    ??'\",\n",
       "     \"VIKA: '  ,        .'\",\n",
       "     \"user: '    ?'\",\n",
       "     \"VIKA: '      .'\",\n",
       "     \"user: '   ?  ?'\",\n",
       "     \"VIKA: '      .'\",\n",
       "     \"user: '    ,    ,   .'\",\n",
       "     \"VIKA: ',         ...   ...        ,  ,     .       .'\",\n",
       "     \"user: '  ?'\",\n",
       "     \"VIKA: '.'\",\n",
       "     \"user: '   ?'\",\n",
       "     \"VIKA: '...'\"],\n",
       "    'AvailableActions': [' ',\n",
       "     '   ',\n",
       "     '   -',\n",
       "     ' '],\n",
       "    'UserInput': '  ??'},\n",
       "   'answer': {'MessageText': '    .',\n",
       "    'Content': {'Action': ''}}},\n",
       "  'topic13': {'prompt': {'History': [\"system: ' -        .       .     JSON   'MessageText'  'Actions',     ( )   .   Actions   ,   .    }.  -       ,      . \",\n",
       "     \"user:    ??'\",\n",
       "     \"VIKA: '  ,        .'\",\n",
       "     \"user: '    ?'\",\n",
       "     \"VIKA: '      .'\",\n",
       "     \"user: '   ?  ?'\",\n",
       "     \"VIKA: '      .'\",\n",
       "     \"user: '    ,    ,   .'\",\n",
       "     \"VIKA: ',         ...   ...        ,  ,     .       .'\",\n",
       "     \"user: '  ?'\",\n",
       "     \"VIKA: '.'\",\n",
       "     \"user: '   ?'\",\n",
       "     \"VIKA: '...'\",\n",
       "     \"user: '  ??'\",\n",
       "     \"VIKA: '    .'\"],\n",
       "    'AvailableActions': [' ',\n",
       "     '   ',\n",
       "     '   -',\n",
       "     ' '],\n",
       "    'UserInput': ', , ,   !'},\n",
       "   'answer': {'MessageText': '   .',\n",
       "    'Content': {'Action': ''}}},\n",
       "  'topic14': {'prompt': {'History': [\"system: ' -        .       .     JSON   'MessageText'  'Actions',     ( )   .   Actions   ,   .    }.  -       ,      . \",\n",
       "     \"user:    ??'\",\n",
       "     \"VIKA: '  ,        .'\",\n",
       "     \"user: '    ?'\",\n",
       "     \"VIKA: '      .'\",\n",
       "     \"user: '   ?  ?'\",\n",
       "     \"VIKA: '      .'\",\n",
       "     \"user: '    ,    ,   .'\",\n",
       "     \"VIKA: ',         ...   ...        ,  ,     .       .'\",\n",
       "     \"user: '  ?'\",\n",
       "     \"VIKA: '.'\",\n",
       "     \"user: '   ?'\",\n",
       "     \"VIKA: '...'\",\n",
       "     \"user: '  ??'\",\n",
       "     \"VIKA: '    .'\",\n",
       "     \"user: ', , ,   !'\",\n",
       "     \"VIKA: '   .'\"],\n",
       "    'AvailableActions': [' ',\n",
       "     '   ',\n",
       "     '   -',\n",
       "     ' '],\n",
       "    'UserInput': '  ?'},\n",
       "   'answer': {'MessageText': '     .     .',\n",
       "    'Content': {'Action': ''}}},\n",
       "  'topic15': {'prompt': {'History': [\"system: ' -        .       .     JSON   'MessageText'  'Actions',     ( )   .   Actions   ,   .    }.  -       ,      . \",\n",
       "     \"user:    ??'\",\n",
       "     \"VIKA: '  ,        .'\",\n",
       "     \"user: '    ?'\",\n",
       "     \"VIKA: '      .'\",\n",
       "     \"user: '   ?  ?'\",\n",
       "     \"VIKA: '      .'\",\n",
       "     \"user: '    ,    ,   .'\",\n",
       "     \"VIKA: ',         ...   ...        ,  ,     .       .'\",\n",
       "     \"user: '  ?'\",\n",
       "     \"VIKA: '.'\",\n",
       "     \"user: '   ?'\",\n",
       "     \"VIKA: '...'\",\n",
       "     \"user: '  ??'\",\n",
       "     \"VIKA: '    .'\",\n",
       "     \"user: ', , ,   !'\",\n",
       "     \"VIKA: '   .'\",\n",
       "     \"user: '  ?'\",\n",
       "     \"VIKA: '     .     .'\"],\n",
       "    'AvailableActions': [' ',\n",
       "     '   ',\n",
       "     '   -',\n",
       "     ' '],\n",
       "    'UserInput': '.   ?  !'},\n",
       "   'answer': {'MessageText': '  .   . .',\n",
       "    'Content': {'Action': ' '}}},\n",
       "  'topic16': {'prompt': {'History': [\"system: ' -        .       .     JSON   'MessageText'  'Actions',     ( )   .   Actions   ,   .    }.  -       ,      . \",\n",
       "     \"user:    ??'\",\n",
       "     \"VIKA: '  ,        .'\",\n",
       "     \"user: '    ?'\",\n",
       "     \"VIKA: '      .'\",\n",
       "     \"user: '   ?  ?'\",\n",
       "     \"VIKA: '      .'\",\n",
       "     \"user: '    ,    ,   .'\",\n",
       "     \"VIKA: ',         ...   ...        ,  ,     .       .'\",\n",
       "     \"user: '  ?'\",\n",
       "     \"VIKA: '.'\",\n",
       "     \"user: '   ?'\",\n",
       "     \"VIKA: '...'\",\n",
       "     \"user: '  ??'\",\n",
       "     \"VIKA: '    .'\",\n",
       "     \"user: ', , ,   !'\",\n",
       "     \"VIKA: '   .'\",\n",
       "     \"user: '  ?'\",\n",
       "     \"VIKA: '     .     .'\"],\n",
       "    'AvailableActions': [' ',\n",
       "     '   ',\n",
       "     '   -',\n",
       "     ' '],\n",
       "    'UserInput': ', .     .    ,   .'},\n",
       "   'answer': {'MessageText': '  ,    .',\n",
       "    'Content': {'Action': ''}}},\n",
       "  'topic17': {'prompt': {'History': [\"system: ' -        .       .     JSON   'MessageText'  'Actions',     ( )   .   Actions   ,   .    }.  -       ,      . \",\n",
       "     \"user:    ??'\",\n",
       "     \"VIKA: '  ,        .'\",\n",
       "     \"user: '    ?'\",\n",
       "     \"VIKA: '      .'\",\n",
       "     \"user: '   ?  ?'\",\n",
       "     \"VIKA: '      .'\",\n",
       "     \"user: '    ,    ,   .'\",\n",
       "     \"VIKA: ',         ...   ...        ,  ,     .       .'\",\n",
       "     \"user: '  ?'\",\n",
       "     \"VIKA: '.'\",\n",
       "     \"user: '   ?'\",\n",
       "     \"VIKA: '...'\",\n",
       "     \"user: '  ??'\",\n",
       "     \"VIKA: '    .'\",\n",
       "     \"user: ', , ,   !'\",\n",
       "     \"VIKA: '   .'\",\n",
       "     \"user: '  ?'\",\n",
       "     \"VIKA: '     .     .'\",\n",
       "     \"user:'.   ?  !'\",\n",
       "     \"VIKA:'  .   . .'\"],\n",
       "    'AvailableActions': [' ',\n",
       "     '   ',\n",
       "     '   -',\n",
       "     ' '],\n",
       "    'UserInput': ', ,   ,   !!!'},\n",
       "   'answer': {'MessageText': '    .   ,    ,   .',\n",
       "    'Content': {'Action': ''}}},\n",
       "  'topic18': {'prompt': {'History': [\"system: ' -        .       .     JSON   'MessageText'  'Actions',     ( )   .   Actions   ,   .    }.  -       ,      . \",\n",
       "     \"user:    ??'\",\n",
       "     \"VIKA: '  ,        .'\",\n",
       "     \"user: '    ?'\",\n",
       "     \"VIKA: '      .'\",\n",
       "     \"user: '   ?  ?'\",\n",
       "     \"VIKA: '      .'\",\n",
       "     \"user: '    ,    ,   .'\",\n",
       "     \"VIKA: ',         ...   ...        ,  ,     .       .'\",\n",
       "     \"user: '  ?'\",\n",
       "     \"VIKA: '.'\",\n",
       "     \"user: '   ?'\",\n",
       "     \"VIKA: '...'\",\n",
       "     \"user: '  ??'\",\n",
       "     \"VIKA: '    .'\",\n",
       "     \"user: ', , ,   !'\",\n",
       "     \"VIKA: '   .'\",\n",
       "     \"user: '  ?'\",\n",
       "     \"VIKA: '     .     .'\",\n",
       "     \"user:'.   ?  !'\",\n",
       "     \"VIKA:'  .   . .'\",\n",
       "     \"user:', ,   !!!'\",\n",
       "     \"VIKA:'    .   ,    ,   .'\"],\n",
       "    'AvailableActions': [' ',\n",
       "     '   ',\n",
       "     '   -',\n",
       "     ' '],\n",
       "    'UserInput': ',   ...'},\n",
       "   'answer': {'MessageText': '.  .',\n",
       "    'Content': {'Action': ''}}},\n",
       "  'topic19': {'prompt': {'History': [\"system: ' -        .       .     JSON   'MessageText'  'Actions',     ( )   .   Actions   ,   .    }.  -       ,      . \",\n",
       "     \"user:    ??'\",\n",
       "     \"VIKA: '  ,        .'\",\n",
       "     \"user: '    ?'\",\n",
       "     \"VIKA: '      .'\",\n",
       "     \"user: '   ?  ?'\",\n",
       "     \"VIKA: '      .'\",\n",
       "     \"user: '    ,    ,   .'\",\n",
       "     \"VIKA: ',         ...   ...        ,  ,     .       .'\",\n",
       "     \"user: '  ?'\",\n",
       "     \"VIKA: '.'\",\n",
       "     \"user: '   ?'\",\n",
       "     \"VIKA: '...'\",\n",
       "     \"user: '  ??'\",\n",
       "     \"VIKA: '    .'\",\n",
       "     \"user: ', , ,   !'\",\n",
       "     \"VIKA: '   .'\",\n",
       "     \"user: '  ?'\",\n",
       "     \"VIKA: '     .     .'\",\n",
       "     \"user:'.   ?  !'\",\n",
       "     \"VIKA:'  .   . .'\",\n",
       "     \"user:', ,   !!!'\",\n",
       "     \"VIKA:'    .   ,    ,   .'\"],\n",
       "    'AvailableActions': [' ',\n",
       "     '   ',\n",
       "     '   -',\n",
       "     ' '],\n",
       "    'UserInput': '    !!!    ,     !'},\n",
       "   'answer': {'MessageText': ',    .   ,     .        .   .',\n",
       "    'Content': {'Action': ' '}}},\n",
       "  'topic20': {'prompt': {'History': [\"system: ' -        .       .     JSON   'MessageText'  'Actions',     ( )   .   Actions   ,   .    }.  -       ,      . \",\n",
       "     \"user:    ??'\",\n",
       "     \"VIKA: '  ,        .'\",\n",
       "     \"user: '    ?'\",\n",
       "     \"VIKA: '      .'\",\n",
       "     \"user: '   ?  ?'\",\n",
       "     \"VIKA: '      .'\",\n",
       "     \"user: '    ,    ,   .'\",\n",
       "     \"VIKA: ',         ...   ...        ,  ,     .       .'\",\n",
       "     \"user: '  ?'\",\n",
       "     \"VIKA: '.'\",\n",
       "     \"user: '   ?'\",\n",
       "     \"VIKA: '...'\",\n",
       "     \"user: '  ??'\",\n",
       "     \"VIKA: '    .'\",\n",
       "     \"user: ', , ,   !'\",\n",
       "     \"VIKA: '   .'\",\n",
       "     \"user: '  ?'\",\n",
       "     \"VIKA: '     .     .'\",\n",
       "     \"user:'.   ?  !'\",\n",
       "     \"VIKA:'  .   . .'\",\n",
       "     \"user:', ,   !!!'\",\n",
       "     \"VIKA:'    .   ,    ,   .'\",\n",
       "     \"user:'    !!!    ,     !'\",\n",
       "     \"VIKA:',    .   ,     .        .   .'\"],\n",
       "    'AvailableActions': [' ',\n",
       "     '   ',\n",
       "     '   -',\n",
       "     ' '],\n",
       "    'UserInput': ' !  '},\n",
       "   'answer': {'MessageText': '.',\n",
       "    'Content': {'Action': ''}}},\n",
       "  '___': {'prompt': {'History': [\"system: '         .       .     JSON   'MessageText'  'Actions',     ( )   .   Actions   ,   .    }.         ,      .'\"],\n",
       "    'AvailableActions': ['  ', '  '],\n",
       "    'UserInput': '!    ?'},\n",
       "   'answer': {'MessageText': '.   ,  -    .          .',\n",
       "    'Content': {'Action': ''}}},\n",
       "  '____': {'prompt': {'History': [\"system: '         .       .     JSON   'MessageText'  'Actions',     ( )   .   Actions   ,   .    }.         ,      .'\",\n",
       "     \"user: '     ?'\",\n",
       "     \"VIKA: '     .      ,  .'\"],\n",
       "    'AvailableActions': ['  ', ' '],\n",
       "    'UserInput': ':   ,  !'},\n",
       "   'answer': {'MessageText': ':   .',\n",
       "    'Content': {'Action': ''}}},\n",
       "  '____': {'prompt': {'History': [\"system: '  ,    ,         ,  -    .     .       ,       -  .         ,    , ,  ,  - .  -  !'\",\n",
       "     \"user: '    ?'\",\n",
       "     \"VIKA: '    ?'\"],\n",
       "    'AvailableActions': ['  ', ' '],\n",
       "    'UserInput': '   ,    .'},\n",
       "   'answer': {'MessageText': '      .',\n",
       "    'Content': {'Action': ''}}},\n",
       "  '_': {'prompt': {'History': [\"system: '  ,    ,         ,  -    .     .       ,       -  .         ,    , ,  ,  - .  -  !'\",\n",
       "     \"user: '. , ,  '\",\n",
       "     \"VIKA: '.      ,        RTUITLab.     RTUITLab,      .'\",\n",
       "     \"user: ' , ,    !'\",\n",
       "     \"VIKA: '       RTUITLab.'\",\n",
       "     \"user: ' ...  3?'\",\n",
       "     \"VIKA: ' .   ,     RTUITLab.'\",\n",
       "     \"user: ', ,   .'\",\n",
       "     \"VIKA: '.'\"],\n",
       "    'AvailableActions': ['  ', ' '],\n",
       "    'UserInput': '  RTUITLab   !'},\n",
       "   'answer': {'MessageText': '  . ,  ,    RTUITLab,   .',\n",
       "    'Content': {'Action': '  '}}},\n",
       "  '__': {'prompt': {'History': [\"system: '  ,    ,         ,  -    .     .       ,       -  .         ,    , ,  ,  - .  -  !'\",\n",
       "     \"user: '  .'\",\n",
       "     \"VIKA: '     ,        RTUITLab.     RTUITLab,      .'\",\n",
       "     \"user: '  !'\",\n",
       "     \"VIKA: '    ,   ,    RTUITLab.'\"],\n",
       "    'AvailableActions': ['  ', ' '],\n",
       "    'UserInput': '  RTUITLab.'},\n",
       "   'answer': {'MessageText': '    RTUITLab,       .',\n",
       "    'Content': {'Action': ''}}},\n",
       "  '___': {'prompt': {'History': [\"system: '  ,    ,         ,  -    .     .       ,       -  .         ,    , ,  ,  - .  -  !'\",\n",
       "     \"user: '   '\",\n",
       "     \"VIKA: '     ,        RTUITLab.     RTUITLab,      .'\"],\n",
       "    'AvailableActions': [],\n",
       "    'UserInput': '8'},\n",
       "   'answer': {'MessageText': ' .   ,     RTUITLab.',\n",
       "    'Content': {'Action': ''}}},\n",
       "  '__': {'prompt': {'History': [\"system: '  ,    ,         ,  -    .     .       ,       -  .         ,    , ,  ,  - .  -  !'\",\n",
       "     \"user: '    ?    RTUITLab.'\",\n",
       "     \"VIKA: '     ,        RTUITLab.     RTUITLab,      .'\"],\n",
       "    'AvailableActions': ['  ', ' '],\n",
       "    'UserInput': '6'},\n",
       "   'answer': {'MessageText': ' ,   .',\n",
       "    'Content': {'Action': '  '}}},\n",
       "  '_rtuitlab': {'prompt': {'History': [\"system: '         .       .     JSON   'MessageText'  'Actions',     ( )   .   Actions   ,   .    }.         ,      .'\",\n",
       "     \"user: '   RTUITLab?'\",\n",
       "     \"VIKA: ' 2100  RTUITLAB         .     RTUITLAB    ,    -   .  , RTUITLAB    , ,   &quot;Arachnoid&quot;,        .'\",\n",
       "     \"user: '     RTUITLab?'\",\n",
       "     \"VIKA: ' ,   .'\"],\n",
       "    'AvailableActions': ['  ', ' '],\n",
       "    'UserInput': ', !'},\n",
       "   'answer': {'MessageText': '   .',\n",
       "    'Content': {'Action': ''}}},\n",
       "  'rtuitlab': {'prompt': {'History': [\"system: '  ,    ,         ,  -    .     .       ,       -  .         ,    , ,  ,  - .  -  !'\"],\n",
       "    'AvailableActions': ['  ',\n",
       "     ' ',\n",
       "     '   '],\n",
       "    'UserInput': '  ,     RTUITLab'},\n",
       "   'answer': {'MessageText': ' 2100  RTUITLAB         .     RTUITLAB    ,    -   .  , RTUITLAB    , ,   &quot;Arachnoid&quot;,        .',\n",
       "    'Content': {'Action': ''}}}}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# train_dataset = pd.read_json(StringIO(json_data)).reset_index(drop=True)\n",
    "# train_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-04T19:02:14.542040Z",
     "start_time": "2024-11-04T19:02:14.516928Z"
    }
   },
   "id": "76619d73544a21ca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               system  \\\n",
       "0           ...   \n",
       "1           ...   \n",
       "2           ...   \n",
       "3           ...   \n",
       "4           ...   \n",
       "5           ...   \n",
       "6           ...   \n",
       "7           ...   \n",
       "8           ...   \n",
       "9           ...   \n",
       "10          ...   \n",
       "11          ...   \n",
       "12          ...   \n",
       "13          ...   \n",
       "14          ...   \n",
       "15          ...   \n",
       "16          ...   \n",
       "17          ...   \n",
       "18          ...   \n",
       "19          ...   \n",
       "20          ...   \n",
       "21          ...   \n",
       "22          ...   \n",
       "23          ...   \n",
       "24          ...   \n",
       "25          ...   \n",
       "26          ...   \n",
       "27          ...   \n",
       "28          ...   \n",
       "29          ...   \n",
       "\n",
       "                                             examples  \n",
       "0   {'prompt': {'History': ['system: ' - ...  \n",
       "1   {'prompt': {'History': ['system: ' - ...  \n",
       "2   {'prompt': {'History': ['system: ' - ...  \n",
       "3   {'prompt': {'History': ['system: ' - ...  \n",
       "4   {'prompt': {'History': ['system: ' - ...  \n",
       "5   {'prompt': {'History': ['system: ' - ...  \n",
       "6   {'prompt': {'History': ['system: ' - ...  \n",
       "7   {'prompt': {'History': ['system: ' - ...  \n",
       "8   {'prompt': {'History': ['system: ' - ...  \n",
       "9   {'prompt': {'History': ['system: ' - ...  \n",
       "10  {'prompt': {'History': ['system: ' - ...  \n",
       "11  {'prompt': {'History': ['system: ' - ...  \n",
       "12  {'prompt': {'History': ['system: ' - ...  \n",
       "13  {'prompt': {'History': ['system: ' - ...  \n",
       "14  {'prompt': {'History': ['system: ' - ...  \n",
       "15  {'prompt': {'History': ['system: ' - ...  \n",
       "16  {'prompt': {'History': ['system: ' - ...  \n",
       "17  {'prompt': {'History': ['system: ' - ...  \n",
       "18  {'prompt': {'History': ['system: ' - ...  \n",
       "19  {'prompt': {'History': ['system: ' - ...  \n",
       "20  {'prompt': {'History': ['system: ' - ...  \n",
       "21  {'prompt': {'History': ['system: '  ...  \n",
       "22  {'prompt': {'History': ['system: '  ...  \n",
       "23  {'prompt': {'History': ['system: '  ...  \n",
       "24  {'prompt': {'History': ['system: '  ...  \n",
       "25  {'prompt': {'History': ['system: '  ...  \n",
       "26  {'prompt': {'History': ['system: '  ...  \n",
       "27  {'prompt': {'History': ['system: '  ...  \n",
       "28  {'prompt': {'History': ['system: '  ...  \n",
       "29  {'prompt': {'History': ['system: '  ...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system</th>\n",
       "      <th>examples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>        ...</td>\n",
       "      <td>{'prompt': {'History': ['system: ' - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>        ...</td>\n",
       "      <td>{'prompt': {'History': ['system: ' - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>        ...</td>\n",
       "      <td>{'prompt': {'History': ['system: ' - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>        ...</td>\n",
       "      <td>{'prompt': {'History': ['system: ' - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>        ...</td>\n",
       "      <td>{'prompt': {'History': ['system: ' - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>        ...</td>\n",
       "      <td>{'prompt': {'History': ['system: ' - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>        ...</td>\n",
       "      <td>{'prompt': {'History': ['system: ' - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>        ...</td>\n",
       "      <td>{'prompt': {'History': ['system: ' - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>        ...</td>\n",
       "      <td>{'prompt': {'History': ['system: ' - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>        ...</td>\n",
       "      <td>{'prompt': {'History': ['system: ' - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>        ...</td>\n",
       "      <td>{'prompt': {'History': ['system: ' - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>        ...</td>\n",
       "      <td>{'prompt': {'History': ['system: ' - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>        ...</td>\n",
       "      <td>{'prompt': {'History': ['system: ' - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>        ...</td>\n",
       "      <td>{'prompt': {'History': ['system: ' - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>        ...</td>\n",
       "      <td>{'prompt': {'History': ['system: ' - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>        ...</td>\n",
       "      <td>{'prompt': {'History': ['system: ' - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>        ...</td>\n",
       "      <td>{'prompt': {'History': ['system: ' - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>        ...</td>\n",
       "      <td>{'prompt': {'History': ['system: ' - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>        ...</td>\n",
       "      <td>{'prompt': {'History': ['system: ' - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>        ...</td>\n",
       "      <td>{'prompt': {'History': ['system: ' - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>        ...</td>\n",
       "      <td>{'prompt': {'History': ['system: ' - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>        ...</td>\n",
       "      <td>{'prompt': {'History': ['system: '  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>        ...</td>\n",
       "      <td>{'prompt': {'History': ['system: '  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>        ...</td>\n",
       "      <td>{'prompt': {'History': ['system: '  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>        ...</td>\n",
       "      <td>{'prompt': {'History': ['system: '  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>        ...</td>\n",
       "      <td>{'prompt': {'History': ['system: '  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>        ...</td>\n",
       "      <td>{'prompt': {'History': ['system: '  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>        ...</td>\n",
       "      <td>{'prompt': {'History': ['system: '  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>        ...</td>\n",
       "      <td>{'prompt': {'History': ['system: '  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>        ...</td>\n",
       "      <td>{'prompt': {'History': ['system: '  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "dataset_to_json(train_dataset, \"../train.json\")\n",
    "dataset_to_json(test_dataset, \"../test.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-08T11:28:26.047934Z",
     "start_time": "2024-11-08T11:28:26.038007Z"
    }
   },
   "id": "96d671a9a4d5aa6c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'system': \"         .       .     JSON   'MessageText'  'Actions',     ( )   .   Actions   ,   .    }.         ,      .\",\n",
       "  'user': \" ,    ,   'system'.      'user'.      'VIKA'. \\n\\n :\\nsystem: ' -        .       .     JSON   'MessageText'  'Actions',     ( )   .   Actions   ,   .    }.  -       ,      . \\n\\n       .\\n :\\n ,  \\n\\n   ,      .\\n :\\n  ?\",\n",
       "  'bot': \"{'MessageText': ', ,   .', 'Content': {'Action': ' '}}\"},\n",
       " {'system': \"         .       .     JSON   'MessageText'  'Actions',     ( )   .   Actions   ,   .    }.         ,      .\",\n",
       "  'user': \" ,    ,   'system'.      'user'.      'VIKA'. \\n\\n :\\nsystem: '         .       .     JSON   'MessageText'  'Actions',     ( )   .   Actions   ,   .    }.         ,      .'\\nuser: '   RTUITLab?'\\nVIKA: ' 2100  RTUITLAB         .     RTUITLAB    ,    -   .  , RTUITLAB    , ,   'Arachnoid',        .'\\n\\n       .\\n :\\n ,   ,  \\n\\n   ,      .\\n :\\n     RTUITLab?\",\n",
       "  'bot': \"{'MessageText': ' ,   .', 'Content': {'Action': ''}}\"},\n",
       " {'system': \"         .       .     JSON   'MessageText'  'Actions',     ( )   .   Actions   ,   .    }.         ,      .\",\n",
       "  'user': \" ,    ,   'system'.      'user'.      'VIKA'. \\n\\n :\\nsystem: '  ,    ,         ,  -    .     .       ,       -  .         ,    , ,  ,  - .  -  !'\\nuser: '    ?'\\nVIKA: '     ,        RTUITLab.     RTUITLab,      .'\\n\\n       .\\n :\\n ,   ,  \\n\\n   ,      .\\n :\\n\",\n",
       "  'bot': \"{'MessageText': ' ,   .', 'Content': {'Action': '  '}}\"},\n",
       " {'system': \"         .       .     JSON   'MessageText'  'Actions',     ( )   .   Actions   ,   .    }.         ,      .\",\n",
       "  'user': \" ,    ,   'system'.      'user'.      'VIKA'. \\n\\n :\\nsystem: '  ,    ,         ,  -    .     .       ,       -  .         ,    , ,  ,  - .  -  !'\\n\\n       .\\n :\\n ,   ,  \\n\\n   ,      .\\n :\\n ,  ,    \",\n",
       "  'bot': \"{'MessageText': '     .     .   .    .', 'Content': {'Action': ''}}\"}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "# dataset = load_dataset(cfg.dataset_name, split=\"all\")\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\n",
    "                'train' : 'train.json',\n",
    "                'test' : 'test.json'\n",
    "    }\n",
    ")\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-08T11:28:27.021127Z",
     "start_time": "2024-11-08T11:28:26.048931Z"
    }
   },
   "id": "cb1fc1af7863bdb4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e070b160de5f4e8893f2dcee292e7329"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6e1f5ff193a7424aac4369bfe7d56d8e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['system', 'user', 'bot'],\n",
       "        num_rows: 35\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['system', 'user', 'bot'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['system', 'user', 'bot'],\n",
      "        num_rows: 21\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T17:18:48.284714Z",
     "start_time": "2024-10-06T17:18:48.275715Z"
    }
   },
   "id": "c698a560fc0309dc",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Description'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[45], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mDescription\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m[\u001B[38;5;241m0\u001B[39m])\n",
      "File \u001B[1;32mH:\\projects\\Face-recognition\\LLM_LoRa\\Lib\\site-packages\\datasets\\dataset_dict.py:72\u001B[0m, in \u001B[0;36mDatasetDict.__getitem__\u001B[1;34m(self, k)\u001B[0m\n\u001B[0;32m     70\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, k) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Dataset:\n\u001B[0;32m     71\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(k, (\u001B[38;5;28mstr\u001B[39m, NamedSplit)) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m---> 72\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__getitem__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mk\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     73\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     74\u001B[0m         available_suggested_splits \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     75\u001B[0m             split \u001B[38;5;28;01mfor\u001B[39;00m split \u001B[38;5;129;01min\u001B[39;00m (Split\u001B[38;5;241m.\u001B[39mTRAIN, Split\u001B[38;5;241m.\u001B[39mTEST, Split\u001B[38;5;241m.\u001B[39mVALIDATION) \u001B[38;5;28;01mif\u001B[39;00m split \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n\u001B[0;32m     76\u001B[0m         ]\n",
      "\u001B[1;31mKeyError\u001B[0m: 'Description'"
     ]
    }
   ],
   "source": [
    "print(dataset[\"Description\"][0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T17:18:49.331043Z",
     "start_time": "2024-10-06T17:18:49.287554Z"
    }
   },
   "id": "99765e2321379f8",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "source": [
    "CUTOFF_LEN = 4000\n",
    "\n",
    "def generate_prompt(data_point):\n",
    "    promt = f\"\"\"<s>system\n",
    "{data_point['system']}</s><s>user\n",
    "{data_point['user']}</s><s>bot\n",
    "{data_point['bot']}</s>\"\"\"\n",
    "    #     print(promt)\n",
    "    return promt\n",
    "\n",
    "\n",
    "def tokenize (prompt, add_eos_token=True):\n",
    "    result = tokenizer(\n",
    "        prompt,\n",
    "        truncation=True,\n",
    "        max_length=CUTOFF_LEN,\n",
    "        padding=True,\n",
    "        return_tensors=None,\n",
    "    )\n",
    "    if (\n",
    "        result[\"input_ids\"][-1] != tokenizer.eos_token_id and len(result[\"input_ids\"]) < CUTOFF_LEN\n",
    "        and add_eos_token\n",
    "    ):\n",
    "\n",
    "        result[\"input_ids\"].append(tokenizer.eos_token_id)\n",
    "        result[\"attention_mask\"].append(1)\n",
    "\n",
    "\n",
    "\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "\n",
    "    return result\n",
    "\n",
    "def generate_and_tokenize_prompt(data_point):\n",
    "    full_prompt = generate_prompt(data_point)\n",
    "    tokenized_full_prompt = tokenize(full_prompt)\n",
    "    return tokenized_full_prompt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-08T11:28:27.026091Z",
     "start_time": "2024-11-08T11:28:27.021127Z"
    }
   },
   "id": "158a984d0a8a82a2",
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "# def format_chat_template(row):\n",
    "#     row_json = [{\"role\": \"user\", \"content\": row[\"Patient\"]},\n",
    "#                {\"role\": \"assistant\", \"content\": row[\"Doctor\"]}]\n",
    "#     row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n",
    "#     return row\n",
    "# \n",
    "# \n",
    "# dataset = dataset.map(\n",
    "# \tformat_chat_template,\n",
    "# \tnum_proc=4,\n",
    "# )\n",
    "train_data = (\n",
    "    dataset[\"train\"].map(generate_and_tokenize_prompt)   \n",
    ")\n",
    "val_data = (\n",
    "    dataset[\"test\"].map(generate_and_tokenize_prompt)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-08T11:28:27.385431Z",
     "start_time": "2024-11-08T11:28:27.027092Z"
    }
   },
   "id": "9a2169eedd5a3a5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/35 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2689cb3038834d9b8cb27c82322f07d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05911425dee945b2bec000428402a93e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "print(train_data[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-07T10:18:33.664092Z",
     "start_time": "2024-10-07T10:18:33.657083Z"
    }
   },
   "id": "15af709af561e4a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'system': \"You are an assistant named Daedalus at an abandoned space station. Respond only in valid JSON with keys 'MessageText' and 'Content', containing potentially one or more actions in the 'Action' key. End your reply with a } character followed by <|eot_id|>\", 'user': '{\\'History\\': [\"system: \\'You are an assistant named Daedalus at an abandoned space station. Respond only in valid JSON with keys \\'MessageText\\' and \\'Content\\', containing potentially one or more actions in the \\'Action\\' key. End your reply with a } character followed by <|eot_id|>.\\'\"], \\'AvailableActions\\': [\\'Turn Off Lights\\'], \\'UserInput\\': \\'Can you turn off the lights?\\'}', 'bot': \"{'MessageText': 'Yes, of course, I will turn off the lights.', 'Content': {'Action': 'Turn Off Lights'}}<|eot_id|>\", 'input_ids': [128000, 45147, 29, 9125, 198, 2675, 527, 459, 18328, 7086, 14569, 291, 87227, 520, 459, 23838, 3634, 8216, 13, 40633, 1193, 304, 2764, 4823, 449, 7039, 364, 2097, 1199, 6, 323, 364, 2831, 518, 8649, 13893, 832, 477, 810, 6299, 304, 279, 364, 2573, 6, 1401, 13, 4060, 701, 10052, 449, 264, 335, 3752, 8272, 555, 220, 128009, 524, 82, 1822, 82, 29, 882, 198, 13922, 13730, 1232, 4482, 9125, 25, 364, 2675, 527, 459, 18328, 7086, 14569, 291, 87227, 520, 459, 23838, 3634, 8216, 13, 40633, 1193, 304, 2764, 4823, 449, 7039, 364, 2097, 1199, 6, 323, 364, 2831, 518, 8649, 13893, 832, 477, 810, 6299, 304, 279, 364, 2573, 6, 1401, 13, 4060, 701, 10052, 449, 264, 335, 3752, 8272, 555, 220, 128009, 3238, 8073, 364, 16892, 13245, 1232, 2570, 19952, 4206, 35270, 4181, 364, 1502, 2566, 1232, 364, 6854, 499, 2543, 1022, 279, 13001, 20837, 5474, 82, 1822, 82, 29, 6465, 198, 13922, 2097, 1199, 1232, 364, 9642, 11, 315, 3388, 11, 358, 690, 2543, 1022, 279, 13001, 16045, 364, 2831, 1232, 5473, 2573, 1232, 364, 19952, 4206, 35270, 23742, 128009, 524, 82, 29, 128257], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [128000, 45147, 29, 9125, 198, 2675, 527, 459, 18328, 7086, 14569, 291, 87227, 520, 459, 23838, 3634, 8216, 13, 40633, 1193, 304, 2764, 4823, 449, 7039, 364, 2097, 1199, 6, 323, 364, 2831, 518, 8649, 13893, 832, 477, 810, 6299, 304, 279, 364, 2573, 6, 1401, 13, 4060, 701, 10052, 449, 264, 335, 3752, 8272, 555, 220, 128009, 524, 82, 1822, 82, 29, 882, 198, 13922, 13730, 1232, 4482, 9125, 25, 364, 2675, 527, 459, 18328, 7086, 14569, 291, 87227, 520, 459, 23838, 3634, 8216, 13, 40633, 1193, 304, 2764, 4823, 449, 7039, 364, 2097, 1199, 6, 323, 364, 2831, 518, 8649, 13893, 832, 477, 810, 6299, 304, 279, 364, 2573, 6, 1401, 13, 4060, 701, 10052, 449, 264, 335, 3752, 8272, 555, 220, 128009, 3238, 8073, 364, 16892, 13245, 1232, 2570, 19952, 4206, 35270, 4181, 364, 1502, 2566, 1232, 364, 6854, 499, 2543, 1022, 279, 13001, 20837, 5474, 82, 1822, 82, 29, 6465, 198, 13922, 2097, 1199, 1232, 364, 9642, 11, 315, 3388, 11, 358, 690, 2543, 1022, 279, 13001, 16045, 364, 2831, 1232, 5473, 2573, 1232, 364, 19952, 4206, 35270, 23742, 128009, 524, 82, 29, 128257]}\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "source": "print(val_data[0])",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-07T10:18:45.222309Z",
     "start_time": "2024-10-07T10:18:45.215720Z"
    }
   },
   "id": "102b3b879f5603e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'system': \"You are an assistant named Daedalus at an abandoned space station. Respond only in valid JSON with keys 'MessageText' and 'Content', containing potentially one or more actions in the 'Action' key. End your reply with a } character followed by <|eot_id|>\", 'user': '{\\'History\\': [\"system: \\'You are an assistant named Daedalus at an abandoned space station. Respond only in valid JSON with keys \\'MessageText\\' and \\'Content\\', containing potentially one or more actions in the \\'Action\\' key. End your reply with a } character followed by <|eot_id|>.\\'\"], \\'AvailableActions\\': [\\'Turn Off Lights\\'], \\'UserInput\\': \\'Can you turn off the lights?\\'}', 'bot': \"{'MessageText': 'Yes, of course, I will turn off the lights.', 'Content': {'Action': 'Turn Off Lights'}}<|eot_id|>\", 'input_ids': [128000, 45147, 29, 9125, 198, 2675, 527, 459, 18328, 7086, 14569, 291, 87227, 520, 459, 23838, 3634, 8216, 13, 40633, 1193, 304, 2764, 4823, 449, 7039, 364, 2097, 1199, 6, 323, 364, 2831, 518, 8649, 13893, 832, 477, 810, 6299, 304, 279, 364, 2573, 6, 1401, 13, 4060, 701, 10052, 449, 264, 335, 3752, 8272, 555, 220, 128009, 524, 82, 1822, 82, 29, 882, 198, 13922, 13730, 1232, 4482, 9125, 25, 364, 2675, 527, 459, 18328, 7086, 14569, 291, 87227, 520, 459, 23838, 3634, 8216, 13, 40633, 1193, 304, 2764, 4823, 449, 7039, 364, 2097, 1199, 6, 323, 364, 2831, 518, 8649, 13893, 832, 477, 810, 6299, 304, 279, 364, 2573, 6, 1401, 13, 4060, 701, 10052, 449, 264, 335, 3752, 8272, 555, 220, 128009, 3238, 8073, 364, 16892, 13245, 1232, 2570, 19952, 4206, 35270, 4181, 364, 1502, 2566, 1232, 364, 6854, 499, 2543, 1022, 279, 13001, 20837, 5474, 82, 1822, 82, 29, 6465, 198, 13922, 2097, 1199, 1232, 364, 9642, 11, 315, 3388, 11, 358, 690, 2543, 1022, 279, 13001, 16045, 364, 2831, 1232, 5473, 2573, 1232, 364, 19952, 4206, 35270, 23742, 128009, 524, 82, 29, 128257], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [128000, 45147, 29, 9125, 198, 2675, 527, 459, 18328, 7086, 14569, 291, 87227, 520, 459, 23838, 3634, 8216, 13, 40633, 1193, 304, 2764, 4823, 449, 7039, 364, 2097, 1199, 6, 323, 364, 2831, 518, 8649, 13893, 832, 477, 810, 6299, 304, 279, 364, 2573, 6, 1401, 13, 4060, 701, 10052, 449, 264, 335, 3752, 8272, 555, 220, 128009, 524, 82, 1822, 82, 29, 882, 198, 13922, 13730, 1232, 4482, 9125, 25, 364, 2675, 527, 459, 18328, 7086, 14569, 291, 87227, 520, 459, 23838, 3634, 8216, 13, 40633, 1193, 304, 2764, 4823, 449, 7039, 364, 2097, 1199, 6, 323, 364, 2831, 518, 8649, 13893, 832, 477, 810, 6299, 304, 279, 364, 2573, 6, 1401, 13, 4060, 701, 10052, 449, 264, 335, 3752, 8272, 555, 220, 128009, 3238, 8073, 364, 16892, 13245, 1232, 2570, 19952, 4206, 35270, 4181, 364, 1502, 2566, 1232, 364, 6854, 499, 2543, 1022, 279, 13001, 20837, 5474, 82, 1822, 82, 29, 6465, 198, 13922, 2097, 1199, 1232, 364, 9642, 11, 315, 3388, 11, 358, 690, 2543, 1022, 279, 13001, 16045, 364, 2831, 1232, 5473, 2573, 1232, 364, 19952, 4206, 35270, 23742, 128009, 524, 82, 29, 128257]}\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "source": [
    "TRAIN_STEPS = 30 \n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=cfg.new_model,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    max_steps=TRAIN_STEPS,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    num_train_epochs=1,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=0.2,\n",
    "    logging_steps=5,\n",
    "    warmup_steps=10,\n",
    "    logging_strategy=\"steps\",\n",
    "    learning_rate=2e-4,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    group_by_length=True,\n",
    "    report_to=\"wandb\",\n",
    "    # remove_unused_columns=False,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-08T11:28:27.433916Z",
     "start_time": "2024-11-08T11:28:27.386429Z"
    }
   },
   "id": "f4f30aeff4013e3",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    peft_config=peft_config, #  ,   \n",
    "    max_seq_length=512,\n",
    "    tokenizer=tokenizer, #   \n",
    "    args=training_arguments,\n",
    "    packing=False,\n",
    "    dataset_kwargs={'skip_prepare_dataset': True}\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-08T11:28:27.802992Z",
     "start_time": "2024-11-08T11:28:27.433916Z"
    }
   },
   "id": "6d90c1aa7d79ce15",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\PyCharm Community Edition 2021.1.1\\projects\\LLM_LoRa\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_kwargs. Will not be supported from version '0.13.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "E:\\PyCharm Community Edition 2021.1.1\\projects\\LLM_LoRa\\venv\\Lib\\site-packages\\trl\\trainer\\sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "E:\\PyCharm Community Edition 2021.1.1\\projects\\LLM_LoRa\\venv\\Lib\\site-packages\\trl\\trainer\\sft_trainer.py:334: UserWarning: You passed a `dataset_kwargs` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T23:39:54.151590Z",
     "start_time": "2024-11-04T23:39:54.139795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import Trainer\n",
    "import transformers\n",
    "data_collator = transformers.DataCollatorForSeq2Seq(\n",
    "    tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    data_collator=data_collator,\n",
    ")"
   ],
   "id": "dcb5519c5b5b1a16",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "trainer.train() "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-08T11:29:10.485645Z",
     "start_time": "2024-11-08T11:28:27.803990Z"
    }
   },
   "id": "f3a6ffb98964ba7f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:37, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.161300</td>\n",
       "      <td>1.545582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.484200</td>\n",
       "      <td>0.449266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.457500</td>\n",
       "      <td>0.332098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.330100</td>\n",
       "      <td>0.323451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.169000</td>\n",
       "      <td>0.311720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=30, training_loss=0.7918395717938741, metrics={'train_runtime': 42.5045, 'train_samples_per_second': 1.412, 'train_steps_per_second': 0.706, 'total_flos': 1462945212235776.0, 'train_loss': 0.7918395717938741, 'epoch': 1.7142857142857144})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "merged_model = model.merge_and_unload()",
   "id": "f89a7c0753a60e80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T20:39:52.264389Z",
     "start_time": "2024-11-04T19:44:36.817582Z"
    }
   },
   "cell_type": "code",
   "source": "merged_model.push_to_hub(cfg.new_model)",
   "id": "3d159a0caabcce23",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "24e9071119d047b2803433ac0e463288"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.65G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2fa869ae8905494b98c1b6e9f5cdfc3d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/1.05G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05b6caecddb84bffbbe789725f525ba0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/ser13volk/llama-3.1-8b-chat-vika/commit/23f89e775d4f2107cfd9116fa4d752348e2a46f3', commit_message='Upload LlamaForCausalLM', commit_description='', oid='23f89e775d4f2107cfd9116fa4d752348e2a46f3', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T21:48:03.171843Z",
     "start_time": "2024-11-04T21:48:03.169086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "self_instruct_dir = '../rulm/self_instruct'\n",
    "checkpoint = \"../../llama-3.1-8b-chat-vika/checkpoint-100\"\n",
    "merged_model_name = 'merged_test_model.pt'\n"
   ],
   "id": "565014f7ce4ce6ea",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T21:48:05.733599Z",
     "start_time": "2024-11-04T21:48:05.730109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "%cd {self_instruct_dir}"
   ],
   "id": "d696ed80bfe7e708",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\PyCharm Community Edition 2021.1.1\\projects\\LLM_LoRa\\LLM_LoRa\\rulm\\self_instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\PyCharm Community Edition 2021.1.1\\projects\\LLM_LoRa\\venv\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T09:39:49.816357Z",
     "start_time": "2024-11-07T09:39:49.700024Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.empty_cache()",
   "id": "21bdaf3f5d937569",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T21:48:21.343159Z",
     "start_time": "2024-11-04T21:48:09.434095Z"
    }
   },
   "cell_type": "code",
   "source": "!python -m src.tools.convert_to_native {checkpoint} {merged_model_name} --device=cuda --enable_offloading",
   "id": "941fa5557b505ec4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading checkpoint shards:   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards:  11%|#1        | 1/9 [00:00<00:06,  1.15it/s]\n",
      "Loading checkpoint shards:  22%|##2       | 2/9 [00:01<00:05,  1.29it/s]\n",
      "Loading checkpoint shards:  33%|###3      | 3/9 [00:02<00:04,  1.30it/s]\n",
      "Loading checkpoint shards:  44%|####4     | 4/9 [00:03<00:04,  1.11it/s]\n",
      "Loading checkpoint shards:  56%|#####5    | 5/9 [00:04<00:03,  1.10it/s]\n",
      "Loading checkpoint shards:  67%|######6   | 6/9 [00:05<00:02,  1.14it/s]\n",
      "Loading checkpoint shards:  78%|#######7  | 7/9 [00:05<00:01,  1.18it/s]\n",
      "Loading checkpoint shards:  89%|########8 | 8/9 [00:06<00:00,  1.28it/s]\n",
      "Loading checkpoint shards: 100%|##########| 9/9 [00:07<00:00,  1.46it/s]\n",
      "Loading checkpoint shards: 100%|##########| 9/9 [00:07<00:00,  1.27it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"E:\\PyCharm Community Edition 2021.1.1\\projects\\LLM_LoRa\\LLM_LoRa\\rulm\\self_instruct\\src\\tools\\convert_to_native.py\", line 115, in <module>\n",
      "    fire.Fire(convert_to_native)\n",
      "  File \"E:\\PyCharm Community Edition 2021.1.1\\projects\\LLM_LoRa\\venv\\Lib\\site-packages\\fire\\core.py\", line 143, in Fire\n",
      "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\PyCharm Community Edition 2021.1.1\\projects\\LLM_LoRa\\venv\\Lib\\site-packages\\fire\\core.py\", line 477, in _Fire\n",
      "    component, remaining_args = _CallAndUpdateTrace(\n",
      "                                ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\PyCharm Community Edition 2021.1.1\\projects\\LLM_LoRa\\venv\\Lib\\site-packages\\fire\\core.py\", line 693, in _CallAndUpdateTrace\n",
      "    component = fn(*varargs, **kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\PyCharm Community Edition 2021.1.1\\projects\\LLM_LoRa\\LLM_LoRa\\rulm\\self_instruct\\src\\tools\\convert_to_native.py\", line 90, in convert_to_native\n",
      "    raise NotImplementedError\n",
      "NotImplementedError\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "path_to_save = \"../Llama-finetuned\"\n",
    "# trainer.save_model(path_to_save)\n",
    "merged_model.save_pretrained(path_to_save)\n",
    "tokenizer.save_pretrained(path_to_save)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "608bd4d66d0aa31c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T21:55:54.257456Z",
     "start_time": "2024-11-04T21:55:54.253496Z"
    }
   },
   "cell_type": "code",
   "source": "%cd ../..",
   "id": "b6b9b71db35080c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\PyCharm Community Edition 2021.1.1\\projects\\LLM_LoRa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\PyCharm Community Edition 2021.1.1\\projects\\LLM_LoRa\\venv\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T21:56:13.454710Z",
     "start_time": "2024-11-04T21:56:13.451784Z"
    }
   },
   "cell_type": "code",
   "source": "%cd LLM_Lora",
   "id": "dd574980b76615bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\PyCharm Community Edition 2021.1.1\\projects\\LLM_LoRa\\LLM_Lora\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T21:49:12.916023Z",
     "start_time": "2024-11-04T21:49:12.912023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_dir = \"../Llama-finetuned\"\n",
    "# checkpoint = \"../llama-3-8b-chat-daedalus/checkpoint-40\"\n",
    "checkpoint = model_dir\n",
    "output_model = \"model-game_v1.gguf\""
   ],
   "id": "f7f7d11a5f632a2e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T21:49:15.058672Z",
     "start_time": "2024-11-04T21:49:15.054702Z"
    }
   },
   "cell_type": "code",
   "source": "%cd llama.cpp",
   "id": "d89680f0bc1a22d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\PyCharm Community Edition 2021.1.1\\projects\\LLM_LoRa\\LLM_LoRa\\llama.cpp\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T21:49:17.825922Z",
     "start_time": "2024-11-04T21:49:16.412377Z"
    }
   },
   "cell_type": "code",
   "source": "!python convert_hf_to_gguf.py {checkpoint} --outfile {output_model} --outtype f16",
   "id": "2104c449f54bfc21",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hf-to-gguf:Loading model: Llama-finetuned\n",
      "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
      "INFO:hf-to-gguf:Exporting model...\n",
      "INFO:hf-to-gguf:rope_freqs.weight,           torch.float32 --> F32, shape = {64}\n",
      "INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00001-of-00002.safetensors'\n",
      "INFO:hf-to-gguf:token_embd.weight,           torch.float16 --> F16, shape = {4096, 128256}\n",
      "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.uint8 --> F32, shape = {29360128}\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\PyCharm Community Edition 2021.1.1\\projects\\LLM_LoRa\\LLM_LoRa\\llama.cpp\\convert_hf_to_gguf.py\", line 4430, in <module>\n",
      "    main()\n",
      "  File \"E:\\PyCharm Community Edition 2021.1.1\\projects\\LLM_LoRa\\LLM_LoRa\\llama.cpp\\convert_hf_to_gguf.py\", line 4424, in main\n",
      "    model_instance.write()\n",
      "  File \"E:\\PyCharm Community Edition 2021.1.1\\projects\\LLM_LoRa\\LLM_LoRa\\llama.cpp\\convert_hf_to_gguf.py\", line 433, in write\n",
      "    self.prepare_tensors()\n",
      "  File \"E:\\PyCharm Community Edition 2021.1.1\\projects\\LLM_LoRa\\LLM_LoRa\\llama.cpp\\convert_hf_to_gguf.py\", line 1653, in prepare_tensors\n",
      "    super().prepare_tensors()\n",
      "  File \"E:\\PyCharm Community Edition 2021.1.1\\projects\\LLM_LoRa\\LLM_LoRa\\llama.cpp\\convert_hf_to_gguf.py\", line 297, in prepare_tensors\n",
      "    for new_name, data_torch in (self.modify_tensors(data_torch, name, bid)):\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\PyCharm Community Edition 2021.1.1\\projects\\LLM_LoRa\\LLM_LoRa\\llama.cpp\\convert_hf_to_gguf.py\", line 1621, in modify_tensors\n",
      "    return [(self.map_tensor_name(name), data_torch)]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\PyCharm Community Edition 2021.1.1\\projects\\LLM_LoRa\\LLM_LoRa\\llama.cpp\\convert_hf_to_gguf.py\", line 213, in map_tensor_name\n",
      "    raise ValueError(f\"Can not map tensor {name!r}\")\n",
      "ValueError: Can not map tensor 'model.layers.0.mlp.down_proj.weight.absmax'\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T11:01:05.187815Z",
     "start_time": "2024-11-05T11:01:01.929555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "#       \n",
    "model_path = \"../Llama-finetuned\"\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=cfg.attn_implementation\n",
    ")\n",
    "# model.load_state_dict(torch.load(\"llama-3-8b-chat-daedalus/checkpoint-40\"), strict=False)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "#     \n",
    "model.eval()\n"
   ],
   "id": "82dfe735f13619f1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "E:\\PyCharm Community Edition 2021.1.1\\projects\\LLM_LoRa\\venv\\Lib\\site-packages\\transformers\\quantizers\\auto.py:186: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "08785ded4d7742e790f3e454d7d6e94d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T11:01:21.808536Z",
     "start_time": "2024-11-05T11:01:09.730707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch \n",
    "input_text = \"\"\" ,    ,   'system'.      'user'.      'VIKA'. \\n\\n :\\nsystem: ' -        .       .     JSON   'MessageText'  'Actions',     ( )   .   Actions   ,   .    }.  -       ,      . \\n\\n       .\\n \\n  \\n\\n   ,      .\\n :\\n  ?\"\n",
    "                \"\"\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "inputs.to(torch.device(\"cuda\"))\n",
    "outputs = model.generate(**inputs, max_new_tokens=256)\n",
    "# \n",
    "#    \n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ],
   "id": "b27db73ad4ae85eb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ,    ,  'system'.      'user'.      'VIKA'. \n",
      "\n",
      " :\n",
      "system: ' -        .       .     JSON   'MessageText'  'Actions',     ( )   .   Actions   ,   .    }.  -       ,      . \n",
      "\n",
      "       .\n",
      " \n",
      "  \n",
      "\n",
      "   ,      .\n",
      " :\n",
      "  ?\"\n",
      "                 }\n",
      "system: {\n",
      "    \"MessageText\": \" .\",\n",
      "    \"Actions\": [\n",
      "        \" \"\n",
      "    ]\n",
      "}\n",
      "VIKA: {\n",
      "    \"MessageText\": \" .\",\n",
      "    \"Actions\": [\n",
      "        \" \"\n",
      "    ]\n",
      "} \n",
      "\n",
      "  :\n",
      " .    . ,   ?..\"\n",
      "                 } \n",
      "\n",
      "VIKA: {\n",
      "    \"MessageText\": \" -  .\",\n",
      "    \"Actions\": [\n",
      "        \" \"\n",
      "    ]\n",
      "} \n",
      "\n",
      "  :\n",
      " -  .    . ,   ?..\"\n",
      "                 } \n",
      "\n",
      "VIKA: {\n",
      "    \"MessageText\": \" -  .\",\n",
      "    \"Actions\": [\n",
      "        \" \"\n",
      "    ]\n",
      "} \n",
      "\n",
      "  :\n",
      " -  .    . ,   ?..\"\n",
      "                 } \n",
      "\n",
      "VIKA: {\n",
      "    \"MessageText\": \" -  .\",\n",
      "   \n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T11:48:28.707426Z",
     "start_time": "2024-10-07T11:47:58.660802Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(model.state_dict(), os.path.join(path_to_save, \"llama3_model.pt\"))",
   "id": "f09f6855e92607dd",
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "del model, tokenizer, trainer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d89163c487a2cd81",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def generate_answer(model, prompt):\n",
    "    chat = [\n",
    "        { \"role\": \"user\", \"content\": prompt },\n",
    "    ]\n",
    "    prompt = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
    "    outputs = model.generate(input_ids=inputs.to(model.device), max_new_tokens=150)\n",
    "\n",
    "    return(tokenizer.decode(outputs[0]))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4bb996ef66d3d76",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "q1 = \"Hello. who are you?\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9bcf2e0bb5699f1a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "generate_answer(model, q1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1aeaf7ba8a5f7e9e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-11-04T22:07:46.775046Z"
    }
   },
   "id": "253c0d1da341c5a4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/9 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "747b21ad01de4064a37ca4c68320283d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "\n",
    "# Configuration\n",
    "model_path = cfg.model_name  # Full-precision base model\n",
    "adapter_path = \"llama-3.1-8b-chat-vika/checkpoint-30\"  # Your LoRA adapter\n",
    "merged_model_path = \"../merged_model_fp16\"\n",
    "\n",
    "# Load the base model in full precision\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=cfg.attn_implementation  # Use 'torch' for better compatibility\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Load and merge the LoRA adapter\n",
    "model = PeftModel.from_pretrained(model, adapter_path)\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "# Save the merged model\n",
    "model.save_pretrained(merged_model_path)\n",
    "tokenizer.save_pretrained(merged_model_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T09:41:45.036007Z",
     "start_time": "2024-11-07T09:39:52.078540Z"
    }
   },
   "id": "7204fe66ca4bd751",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/9 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d414a419c88848e1a781e232806f30bf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('merged_model_fp16\\\\tokenizer_config.json',\n",
       " 'merged_model_fp16\\\\special_tokens_map.json',\n",
       " 'merged_model_fp16\\\\tokenizer.json')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T09:42:13.715441Z",
     "start_time": "2024-11-07T09:42:13.709632Z"
    }
   },
   "cell_type": "code",
   "source": "%cd llama.cpp",
   "id": "24897a0f75afe836",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\PyCharm Community Edition 2021.1.1\\projects\\LLM_LoRa\\LLM_LoRa\\llama.cpp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\PyCharm Community Edition 2021.1.1\\projects\\LLM_LoRa\\venv\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T09:43:53.874313Z",
     "start_time": "2024-11-07T09:42:14.346144Z"
    }
   },
   "cell_type": "code",
   "source": "!python convert_hf_to_gguf.py ../merged_model_fp16 --outfile model-game_v2_2_1.gguf --outtype f16\n",
   "id": "9a2e4da252631725",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hf-to-gguf:Loading model: merged_model_fp16\n",
      "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
      "INFO:hf-to-gguf:Exporting model...\n",
      "INFO:hf-to-gguf:rope_freqs.weight,           torch.float32 --> F32, shape = {64}\n",
      "INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00001-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:token_embd.weight,           torch.float16 --> F16, shape = {4096, 128256}\n",
      "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00002-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00003-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.28.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.28.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.28.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.28.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.28.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.28.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.28.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.28.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.28.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.29.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.29.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.29.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.29.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.29.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.29.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.29.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.29.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.29.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.30.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.30.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.30.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.30.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.30.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.30.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.30.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.30.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.30.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.31.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.31.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.31.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.31.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.31.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.31.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00004-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:output.weight,               torch.float16 --> F16, shape = {4096, 128256}\n",
      "INFO:hf-to-gguf:blk.31.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.31.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.31.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:output_norm.weight,          torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:Set meta model\n",
      "INFO:hf-to-gguf:Set model parameters\n",
      "INFO:hf-to-gguf:gguf: context length = 131072\n",
      "INFO:hf-to-gguf:gguf: embedding length = 4096\n",
      "INFO:hf-to-gguf:gguf: feed forward length = 14336\n",
      "INFO:hf-to-gguf:gguf: head count = 32\n",
      "INFO:hf-to-gguf:gguf: key-value head count = 8\n",
      "INFO:hf-to-gguf:gguf: rope theta = 500000.0\n",
      "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
      "INFO:hf-to-gguf:gguf: file type = 1\n",
      "INFO:hf-to-gguf:Set model tokenizer\n",
      "INFO:gguf.vocab:Adding 280147 merge(s).\n",
      "INFO:gguf.vocab:Setting special token type bos to 128000\n",
      "INFO:gguf.vocab:Setting special token type eos to 128009\n",
      "INFO:gguf.vocab:Setting special token type pad to 128009\n",
      "INFO:gguf.vocab:Setting chat_template to {{ '<|begin_of_text|>' }}{% if messages[0]['role'] == 'system' %}{% set system_message = messages[0]['content'] %}{% endif %}{% if system_message is defined %}{{ '<|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "' + system_message + '<|eot_id|>' }}{% endif %}{% for message in messages %}{% set content = message['content'] %}{% if message['role'] == 'user' %}{{ '<|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "' + content + '<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "' }}{% elif message['role'] == 'assistant' %}{{ content + '<|eot_id|>' }}{% endif %}{% endfor %}\n",
      "INFO:hf-to-gguf:Set model quantization version\n",
      "INFO:gguf.gguf_writer:Writing the following files:\n",
      "INFO:gguf.gguf_writer:model-game_v2_2_1.gguf: n_tensors = 292, total_size = 16.1G\n",
      "\n",
      "Writing:   0%|          | 0.00/16.1G [00:00<?, ?byte/s]\n",
      "Writing:   7%|6         | 1.05G/16.1G [00:06<01:31, 164Mbyte/s]\n",
      "Writing:   7%|7         | 1.17G/16.1G [00:07<01:29, 167Mbyte/s]\n",
      "Writing:   8%|8         | 1.29G/16.1G [00:07<01:26, 170Mbyte/s]\n",
      "Writing:   9%|8         | 1.40G/16.1G [00:08<01:23, 175Mbyte/s]\n",
      "Writing:   9%|8         | 1.44G/16.1G [00:08<01:20, 182Mbyte/s]\n",
      "Writing:   9%|9         | 1.48G/16.1G [00:08<01:17, 189Mbyte/s]\n",
      "Writing:  10%|9         | 1.60G/16.1G [00:09<01:12, 199Mbyte/s]\n",
      "Writing:  11%|#         | 1.72G/16.1G [00:09<01:12, 199Mbyte/s]\n",
      "Writing:  11%|#1        | 1.84G/16.1G [00:10<01:11, 200Mbyte/s]\n",
      "Writing:  12%|#1        | 1.88G/16.1G [00:10<01:07, 212Mbyte/s]\n",
      "Writing:  12%|#1        | 1.91G/16.1G [00:10<01:03, 221Mbyte/s]\n",
      "Writing:  13%|#2        | 2.04G/16.1G [00:11<01:17, 182Mbyte/s]\n",
      "Writing:  13%|#3        | 2.16G/16.1G [00:11<01:14, 186Mbyte/s]\n",
      "Writing:  14%|#4        | 2.28G/16.1G [00:12<01:21, 169Mbyte/s]\n",
      "Writing:  14%|#4        | 2.32G/16.1G [00:12<01:15, 181Mbyte/s]\n",
      "Writing:  15%|#4        | 2.36G/16.1G [00:12<01:08, 201Mbyte/s]\n",
      "Writing:  15%|#5        | 2.48G/16.1G [00:13<01:05, 208Mbyte/s]\n",
      "Writing:  16%|#6        | 2.59G/16.1G [00:14<01:12, 185Mbyte/s]\n",
      "Writing:  17%|#6        | 2.71G/16.1G [00:14<01:10, 188Mbyte/s]\n",
      "Writing:  17%|#7        | 2.75G/16.1G [00:15<01:05, 203Mbyte/s]\n",
      "Writing:  17%|#7        | 2.79G/16.1G [00:15<01:02, 212Mbyte/s]\n",
      "Writing:  18%|#8        | 2.91G/16.1G [00:15<01:01, 213Mbyte/s]\n",
      "Writing:  19%|#8        | 3.03G/16.1G [00:16<01:04, 203Mbyte/s]\n",
      "Writing:  20%|#9        | 3.15G/16.1G [00:16<01:03, 202Mbyte/s]\n",
      "Writing:  20%|#9        | 3.19G/16.1G [00:17<00:59, 216Mbyte/s]\n",
      "Writing:  20%|##        | 3.22G/16.1G [00:17<00:56, 226Mbyte/s]\n",
      "Writing:  21%|##        | 3.35G/16.1G [00:17<00:58, 219Mbyte/s]\n",
      "Writing:  22%|##1       | 3.47G/16.1G [00:18<01:17, 162Mbyte/s]\n",
      "Writing:  22%|##2       | 3.58G/16.1G [00:19<01:12, 172Mbyte/s]\n",
      "Writing:  23%|##2       | 3.63G/16.1G [00:19<01:06, 188Mbyte/s]\n",
      "Writing:  23%|##2       | 3.66G/16.1G [00:19<01:01, 200Mbyte/s]\n",
      "Writing:  24%|##3       | 3.79G/16.1G [00:20<01:00, 203Mbyte/s]\n",
      "Writing:  24%|##4       | 3.90G/16.1G [00:20<01:00, 202Mbyte/s]\n",
      "Writing:  25%|##5       | 4.02G/16.1G [00:21<01:01, 196Mbyte/s]\n",
      "Writing:  25%|##5       | 4.06G/16.1G [00:21<00:56, 212Mbyte/s]\n",
      "Writing:  26%|##5       | 4.10G/16.1G [00:21<00:53, 222Mbyte/s]\n",
      "Writing:  26%|##6       | 4.22G/16.1G [00:22<00:55, 212Mbyte/s]\n",
      "Writing:  27%|##7       | 4.34G/16.1G [00:22<00:58, 201Mbyte/s]\n",
      "Writing:  28%|##7       | 4.46G/16.1G [00:23<00:58, 198Mbyte/s]\n",
      "Writing:  28%|##8       | 4.50G/16.1G [00:23<00:54, 213Mbyte/s]\n",
      "Writing:  28%|##8       | 4.53G/16.1G [00:23<00:51, 224Mbyte/s]\n",
      "Writing:  29%|##9       | 4.66G/16.1G [00:24<00:52, 215Mbyte/s]\n",
      "Writing:  30%|##9       | 4.78G/16.1G [00:24<00:54, 207Mbyte/s]\n",
      "Writing:  30%|###       | 4.89G/16.1G [00:25<00:54, 203Mbyte/s]\n",
      "Writing:  31%|###       | 4.93G/16.1G [00:25<00:52, 214Mbyte/s]\n",
      "Writing:  31%|###       | 4.97G/16.1G [00:25<00:49, 224Mbyte/s]\n",
      "Writing:  32%|###1      | 5.09G/16.1G [00:26<01:01, 179Mbyte/s]\n",
      "Writing:  32%|###2      | 5.21G/16.1G [00:27<00:58, 184Mbyte/s]\n",
      "Writing:  33%|###3      | 5.33G/16.1G [00:27<00:57, 188Mbyte/s]\n",
      "Writing:  33%|###3      | 5.37G/16.1G [00:27<00:52, 202Mbyte/s]\n",
      "Writing:  34%|###3      | 5.40G/16.1G [00:28<00:49, 213Mbyte/s]\n",
      "Writing:  34%|###4      | 5.53G/16.1G [00:28<00:49, 213Mbyte/s]\n",
      "Writing:  35%|###5      | 5.65G/16.1G [00:29<00:49, 209Mbyte/s]\n",
      "Writing:  36%|###5      | 5.77G/16.1G [00:29<00:48, 212Mbyte/s]\n",
      "Writing:  36%|###6      | 5.84G/16.1G [00:30<00:42, 238Mbyte/s]\n",
      "Writing:  37%|###7      | 5.97G/16.1G [00:30<00:44, 226Mbyte/s]\n",
      "Writing:  38%|###7      | 6.08G/16.1G [00:31<00:44, 225Mbyte/s]\n",
      "Writing:  39%|###8      | 6.20G/16.1G [00:31<00:45, 217Mbyte/s]\n",
      "Writing:  39%|###9      | 6.28G/16.1G [00:31<00:40, 241Mbyte/s]\n",
      "Writing:  40%|###9      | 6.40G/16.1G [00:32<00:40, 240Mbyte/s]\n",
      "Writing:  41%|####      | 6.52G/16.1G [00:33<00:49, 193Mbyte/s]\n",
      "Writing:  41%|####1     | 6.64G/16.1G [00:34<01:01, 154Mbyte/s]\n",
      "Writing:  42%|####1     | 6.68G/16.1G [00:34<00:55, 168Mbyte/s]\n",
      "Writing:  42%|####1     | 6.71G/16.1G [00:34<00:52, 179Mbyte/s]\n",
      "Writing:  43%|####2     | 6.84G/16.1G [00:35<00:48, 189Mbyte/s]\n",
      "Writing:  43%|####3     | 6.96G/16.1G [00:35<00:46, 197Mbyte/s]\n",
      "Writing:  44%|####4     | 7.07G/16.1G [00:36<00:44, 200Mbyte/s]\n",
      "Writing:  45%|####4     | 7.15G/16.1G [00:36<00:39, 226Mbyte/s]\n",
      "Writing:  45%|####5     | 7.28G/16.1G [00:37<00:38, 228Mbyte/s]\n",
      "Writing:  46%|####6     | 7.39G/16.1G [00:37<00:38, 223Mbyte/s]\n",
      "Writing:  47%|####6     | 7.51G/16.1G [00:38<00:38, 220Mbyte/s]\n",
      "Writing:  47%|####7     | 7.55G/16.1G [00:38<00:36, 233Mbyte/s]\n",
      "Writing:  47%|####7     | 7.59G/16.1G [00:38<00:33, 251Mbyte/s]\n",
      "Writing:  48%|####8     | 7.71G/16.1G [00:38<00:35, 235Mbyte/s]\n",
      "Writing:  49%|####8     | 7.83G/16.1G [00:39<00:35, 229Mbyte/s]\n",
      "Writing:  49%|####9     | 7.95G/16.1G [00:40<00:35, 228Mbyte/s]\n",
      "Writing:  50%|####9     | 8.02G/16.1G [00:40<00:31, 254Mbyte/s]\n",
      "Writing:  51%|#####     | 8.15G/16.1G [00:40<00:31, 250Mbyte/s]\n",
      "Writing:  51%|#####1    | 8.27G/16.1G [00:41<00:32, 242Mbyte/s]\n",
      "Writing:  52%|#####2    | 8.38G/16.1G [00:41<00:33, 226Mbyte/s]\n",
      "Writing:  52%|#####2    | 8.42G/16.1G [00:41<00:31, 241Mbyte/s]\n",
      "Writing:  53%|#####2    | 8.47G/16.1G [00:42<00:29, 257Mbyte/s]\n",
      "Writing:  53%|#####3    | 8.58G/16.1G [00:43<00:55, 135Mbyte/s]\n",
      "Writing:  54%|#####4    | 8.70G/16.1G [00:44<00:52, 140Mbyte/s]\n",
      "Writing:  55%|#####4    | 8.82G/16.1G [00:44<00:46, 157Mbyte/s]\n",
      "Writing:  55%|#####5    | 8.86G/16.1G [00:45<00:41, 173Mbyte/s]\n",
      "Writing:  55%|#####5    | 8.89G/16.1G [00:45<00:38, 185Mbyte/s]\n",
      "Writing:  56%|#####6    | 9.02G/16.1G [00:45<00:35, 200Mbyte/s]\n",
      "Writing:  57%|#####6    | 9.14G/16.1G [00:46<00:33, 205Mbyte/s]\n",
      "Writing:  58%|#####7    | 9.26G/16.1G [00:46<00:33, 204Mbyte/s]\n",
      "Writing:  58%|#####7    | 9.30G/16.1G [00:46<00:30, 221Mbyte/s]\n",
      "Writing:  58%|#####8    | 9.34G/16.1G [00:47<00:28, 240Mbyte/s]\n",
      "Writing:  59%|#####8    | 9.46G/16.1G [00:47<00:28, 229Mbyte/s]\n",
      "Writing:  59%|#####9    | 9.50G/16.1G [00:47<00:26, 246Mbyte/s]\n",
      "Writing:  59%|#####9    | 9.53G/16.1G [00:47<00:27, 242Mbyte/s]\n",
      "Writing:  60%|######    | 9.66G/16.1G [00:48<00:27, 231Mbyte/s]\n",
      "Writing:  61%|######    | 9.78G/16.1G [00:48<00:28, 221Mbyte/s]\n",
      "Writing:  62%|######1   | 9.89G/16.1G [00:49<00:28, 216Mbyte/s]\n",
      "Writing:  62%|######1   | 9.93G/16.1G [00:49<00:26, 232Mbyte/s]\n",
      "Writing:  62%|######2   | 9.97G/16.1G [00:49<00:25, 242Mbyte/s]\n",
      "Writing:  63%|######2   | 10.1G/16.1G [00:50<00:30, 198Mbyte/s]\n",
      "Writing:  64%|######3   | 10.2G/16.1G [00:51<00:29, 201Mbyte/s]\n",
      "Writing:  64%|######4   | 10.3G/16.1G [00:51<00:28, 198Mbyte/s]\n",
      "Writing:  65%|######5   | 10.4G/16.1G [00:52<00:27, 202Mbyte/s]\n",
      "Writing:  66%|######5   | 10.6G/16.1G [00:52<00:26, 205Mbyte/s]\n",
      "Writing:  66%|######6   | 10.6G/16.1G [00:52<00:24, 220Mbyte/s]\n",
      "Writing:  66%|######6   | 10.6G/16.1G [00:53<00:22, 238Mbyte/s]\n",
      "Writing:  67%|######7   | 10.8G/16.1G [00:53<00:23, 228Mbyte/s]\n",
      "Writing:  68%|######7   | 10.9G/16.1G [00:54<00:23, 222Mbyte/s]\n",
      "Writing:  68%|######8   | 11.0G/16.1G [00:54<00:23, 219Mbyte/s]\n",
      "Writing:  69%|######8   | 11.0G/16.1G [00:54<00:21, 235Mbyte/s]\n",
      "Writing:  69%|######9   | 11.1G/16.1G [00:54<00:19, 254Mbyte/s]\n",
      "Writing:  70%|######9   | 11.2G/16.1G [00:55<00:21, 231Mbyte/s]\n",
      "Writing:  70%|#######   | 11.3G/16.1G [00:56<00:21, 219Mbyte/s]\n",
      "Writing:  71%|#######1  | 11.4G/16.1G [00:56<00:22, 207Mbyte/s]\n",
      "Writing:  71%|#######1  | 11.5G/16.1G [00:56<00:20, 224Mbyte/s]\n",
      "Writing:  72%|#######1  | 11.5G/16.1G [00:56<00:19, 233Mbyte/s]\n",
      "Writing:  72%|#######2  | 11.6G/16.1G [00:57<00:19, 225Mbyte/s]\n",
      "Writing:  73%|#######3  | 11.8G/16.1G [00:58<00:19, 217Mbyte/s]\n",
      "Writing:  74%|#######3  | 11.9G/16.1G [00:58<00:19, 216Mbyte/s]\n",
      "Writing:  74%|#######4  | 11.9G/16.1G [00:58<00:17, 232Mbyte/s]\n",
      "Writing:  74%|#######4  | 12.0G/16.1G [00:58<00:16, 251Mbyte/s]\n",
      "Writing:  75%|#######5  | 12.1G/16.1G [00:59<00:17, 232Mbyte/s]\n",
      "Writing:  76%|#######5  | 12.2G/16.1G [00:59<00:17, 218Mbyte/s]\n",
      "Writing:  77%|#######6  | 12.3G/16.1G [01:00<00:17, 212Mbyte/s]\n",
      "Writing:  77%|#######6  | 12.4G/16.1G [01:00<00:16, 222Mbyte/s]\n",
      "Writing:  77%|#######7  | 12.4G/16.1G [01:00<00:15, 233Mbyte/s]\n",
      "Writing:  78%|#######7  | 12.5G/16.1G [01:01<00:15, 223Mbyte/s]\n",
      "Writing:  79%|#######8  | 12.6G/16.1G [01:01<00:16, 207Mbyte/s]\n",
      "Writing:  79%|#######9  | 12.7G/16.1G [01:02<00:15, 208Mbyte/s]\n",
      "Writing:  80%|#######9  | 12.8G/16.1G [01:02<00:14, 225Mbyte/s]\n",
      "Writing:  80%|#######9  | 12.8G/16.1G [01:02<00:13, 244Mbyte/s]\n",
      "Writing:  81%|########  | 12.9G/16.1G [01:03<00:13, 223Mbyte/s]\n",
      "Writing:  81%|########1 | 13.1G/16.1G [01:03<00:13, 216Mbyte/s]\n",
      "Writing:  82%|########2 | 13.2G/16.1G [01:04<00:13, 213Mbyte/s]\n",
      "Writing:  82%|########2 | 13.2G/16.1G [01:04<00:12, 229Mbyte/s]\n",
      "Writing:  83%|########2 | 13.3G/16.1G [01:04<00:11, 238Mbyte/s]\n",
      "Writing:  83%|########3 | 13.4G/16.1G [01:05<00:11, 227Mbyte/s]\n",
      "Writing:  84%|########4 | 13.5G/16.1G [01:05<00:11, 216Mbyte/s]\n",
      "Writing:  85%|########4 | 13.6G/16.1G [01:06<00:11, 210Mbyte/s]\n",
      "Writing:  85%|########5 | 13.7G/16.1G [01:06<00:11, 213Mbyte/s]\n",
      "Writing:  85%|########5 | 13.7G/16.1G [01:06<00:10, 224Mbyte/s]\n",
      "Writing:  86%|########6 | 13.8G/16.1G [01:09<00:25, 86.6Mbyte/s]\n",
      "Writing:  87%|########6 | 13.9G/16.1G [01:09<00:19, 108Mbyte/s] \n",
      "Writing:  88%|########7 | 14.1G/16.1G [01:13<00:33, 60.8Mbyte/s]\n",
      "Writing:  88%|########7 | 14.1G/16.1G [01:14<00:32, 61.2Mbyte/s]\n",
      "Writing:  88%|########7 | 14.1G/16.1G [01:14<00:31, 60.5Mbyte/s]\n",
      "Writing:  89%|########8 | 14.3G/16.1G [01:18<00:39, 45.9Mbyte/s]\n",
      "Writing:  89%|########9 | 14.4G/16.1G [01:20<00:36, 46.5Mbyte/s]\n",
      "Writing:  90%|######### | 14.5G/16.1G [01:21<00:24, 63.0Mbyte/s]\n",
      "Writing:  90%|######### | 14.5G/16.1G [01:21<00:21, 72.0Mbyte/s]\n",
      "Writing:  91%|######### | 14.6G/16.1G [01:21<00:18, 81.0Mbyte/s]\n",
      "Writing:  91%|#########1| 14.7G/16.1G [01:22<00:12, 107Mbyte/s] \n",
      "Writing:  92%|#########2| 14.8G/16.1G [01:22<00:09, 127Mbyte/s]\n",
      "Writing:  92%|#########2| 14.9G/16.1G [01:23<00:08, 141Mbyte/s]\n",
      "Writing:  93%|#########2| 14.9G/16.1G [01:23<00:07, 153Mbyte/s]\n",
      "Writing:  99%|#########9| 15.9G/16.1G [01:30<00:00, 138Mbyte/s]\n",
      "Writing: 100%|#########9| 16.1G/16.1G [01:31<00:00, 143Mbyte/s]\n",
      "Writing: 100%|##########| 16.1G/16.1G [01:31<00:00, 175Mbyte/s]\n",
      "INFO:hf-to-gguf:Model successfully exported to model-game_v2_2_1.gguf\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e8b873590b75bac1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T22:51:06.505726Z",
     "start_time": "2024-11-04T22:51:06.473410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!./quantize merged_model_fp16.gguf llama-merged-q4_0.gguf q4_0\n",
    "\n"
   ],
   "id": "91474e4ded1af91c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\".\"     \n",
      ",     .\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T22:47:23.138610Z",
     "start_time": "2024-11-04T22:47:23.064280Z"
    }
   },
   "cell_type": "code",
   "source": "!./main -m llama-merged-model.gguf --interactive -n 256\n",
   "id": "bf876cceee359c37",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\".\"     \n",
      ",     .\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7e2583105aec3f9e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
