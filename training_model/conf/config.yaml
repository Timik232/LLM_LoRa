# conf/config.yaml
#defaults:
#  - override /logging: default
defaults:
  - _self_  # Add _self_ first to include the current config in composition
  - override hydra/job_logging: disabled  # Properly override Hydra's logging
  - override hydra/hydra_logging: disabled


model:
  model_name: "AnatoliiPotapov/T-lite-instruct-0.1"
  dataset_name: "data/judge.json"
  test_dataset_name: "judge.json"
  new_model: "judge-model"
  torch_dtype: "float16"
  attn_implementation: "eager"
  train_steps: 60
  outfile: "judge.gguf"
  quant_postfix: "_q8"
  qtype: "q8_0"
  version: "v5"
  lora_r: 16
  lora_alpha: 32
  lora_dropout: 0.1

training:
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  gradient_accumulation_steps: 2
  num_train_epochs: 3
  eval_steps: 20
  logging_steps: 5
  warmup_steps: 2
  learning_rate: 2e-5
  fp16: false
  bf16: false
  weight_decay: 0.05
  max_seq_length: 2048
  optim: "adamw_8bit"
  neftune_noise_alpha: 0
  gradient_checkpointing: true
  save_total_limit: 3
  load_best: false

paths:
  data_dir: "data"
  merged_model_path: "merged_model_fp16"
  output_dir: "Llama-finetuned"
  venv_python_path: "T:/projects/LLM_LoRa/venv/Scripts/python.exe"
  llama_cpp_dir: "llama.cpp"
  lmstudio_path: "T:/lm-studio/models/game-model"

other:
  cutoff_len: 2048
  wandb_prject: "Fine-tune on judge"

hydra:
  run:
    dir: .
  job:
    chdir: true  # Address future Hydra working dir change warning
