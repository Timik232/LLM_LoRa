{
  "os": "Windows-10-10.0.19045-SP0",
  "python": "3.11.0",
  "startedAt": "2024-10-24T09:40:01.242242Z",
  "program": "LLM_LoRa/llama31_train.ipynb",
  "git": {
    "remote": "https://github.com/Timik232/LLM_LoRa.git",
    "commit": "e764e8dae587c7ca0dc4652a57e0794fa24ebdd3"
  },
  "email": "komolov.timurka@mail.ru",
  "root": "E:\\PyCharm Community Edition 2021.1.1\\projects\\LLM_LoRa\\LLM_LoRa",
  "host": "WIN-K4H606SUNPL",
  "username": "user",
  "executable": "E:\\PyCharm Community Edition 2021.1.1\\projects\\LLM_LoRa\\venv\\Scripts\\python.exe",
  "cpu_count": 14,
  "cpu_count_logical": 20,
  "gpu": "[NVIDIA GeForce RTX 3090]",
  "gpu_count": 1,
  "disk": {
    "/": {
      "total": "1995568050176",
      "used": "1719039164416"
    }
  },
  "memory": {
    "total": "68481994752"
  },
  "cpu": {
    "count": 14,
    "countLogical": 20
  },
  "gpu_nvidia": [
    {
      "name": "NVIDIA GeForce RTX 3090",
      "memoryTotal": "25769803776",
      "cudaCores": 10496,
      "architecture": "Ampere"
    }
  ],
  "cudaVersion": "12.5"
}